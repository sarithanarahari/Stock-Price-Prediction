{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "%matplotlib inline\n",
    "\n",
    "stocksdf = pd.read_csv(r\"Stock_Price_MAX.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = stocksdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj_Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000/3/27</td>\n",
       "      <td>3.812500</td>\n",
       "      <td>4.156250</td>\n",
       "      <td>3.812500</td>\n",
       "      <td>4.125000</td>\n",
       "      <td>4.125000</td>\n",
       "      <td>3675600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000/3/28</td>\n",
       "      <td>4.125000</td>\n",
       "      <td>4.125000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.015625</td>\n",
       "      <td>4.015625</td>\n",
       "      <td>1077600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000/3/29</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.031250</td>\n",
       "      <td>3.953125</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>437200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000/3/30</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.843750</td>\n",
       "      <td>3.843750</td>\n",
       "      <td>3.843750</td>\n",
       "      <td>1883600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000/3/31</td>\n",
       "      <td>3.734375</td>\n",
       "      <td>3.734375</td>\n",
       "      <td>3.390625</td>\n",
       "      <td>3.390625</td>\n",
       "      <td>3.390625</td>\n",
       "      <td>7931600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date      Open      High       Low     Close  Adj_Close   Volume\n",
       "0  2000/3/27  3.812500  4.156250  3.812500  4.125000   4.125000  3675600\n",
       "1  2000/3/28  4.125000  4.125000  4.000000  4.015625   4.015625  1077600\n",
       "2  2000/3/29  4.000000  4.031250  3.953125  4.000000   4.000000   437200\n",
       "3  2000/3/30  4.000000  4.000000  3.843750  3.843750   3.843750  1883600\n",
       "4  2000/3/31  3.734375  3.734375  3.390625  3.390625   3.390625  7931600"
      ]
     },
     "execution_count": 694,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj_Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4392.000000</td>\n",
       "      <td>4392.000000</td>\n",
       "      <td>4392.000000</td>\n",
       "      <td>4392.000000</td>\n",
       "      <td>4392.000000</td>\n",
       "      <td>4.392000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>30.562539</td>\n",
       "      <td>30.893618</td>\n",
       "      <td>30.238833</td>\n",
       "      <td>30.572580</td>\n",
       "      <td>30.572580</td>\n",
       "      <td>1.884027e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>29.914758</td>\n",
       "      <td>30.210974</td>\n",
       "      <td>29.615761</td>\n",
       "      <td>29.905778</td>\n",
       "      <td>29.905778</td>\n",
       "      <td>1.621609e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.296875</td>\n",
       "      <td>3.390625</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>1.904000e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.718125</td>\n",
       "      <td>8.803125</td>\n",
       "      <td>8.625000</td>\n",
       "      <td>8.712500</td>\n",
       "      <td>8.712500</td>\n",
       "      <td>1.088800e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>14.766250</td>\n",
       "      <td>14.981250</td>\n",
       "      <td>14.662500</td>\n",
       "      <td>14.767500</td>\n",
       "      <td>14.767500</td>\n",
       "      <td>1.539300e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>42.546248</td>\n",
       "      <td>43.051249</td>\n",
       "      <td>42.086249</td>\n",
       "      <td>42.539999</td>\n",
       "      <td>42.539999</td>\n",
       "      <td>2.188900e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>121.080002</td>\n",
       "      <td>121.750000</td>\n",
       "      <td>120.169998</td>\n",
       "      <td>121.360001</td>\n",
       "      <td>121.360001</td>\n",
       "      <td>4.641260e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Open         High          Low        Close    Adj_Close  \\\n",
       "count  4392.000000  4392.000000  4392.000000  4392.000000  4392.000000   \n",
       "mean     30.562539    30.893618    30.238833    30.572580    30.572580   \n",
       "std      29.914758    30.210974    29.615761    29.905778    29.905778   \n",
       "min       3.296875     3.390625     3.000000     3.250000     3.250000   \n",
       "25%       8.718125     8.803125     8.625000     8.712500     8.712500   \n",
       "50%      14.766250    14.981250    14.662500    14.767500    14.767500   \n",
       "75%      42.546248    43.051249    42.086249    42.539999    42.539999   \n",
       "max     121.080002   121.750000   120.169998   121.360001   121.360001   \n",
       "\n",
       "             Volume  \n",
       "count  4.392000e+03  \n",
       "mean   1.884027e+06  \n",
       "std    1.621609e+06  \n",
       "min    1.904000e+05  \n",
       "25%    1.088800e+06  \n",
       "50%    1.539300e+06  \n",
       "75%    2.188900e+06  \n",
       "max    4.641260e+07  "
      ]
     },
     "execution_count": 695,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.drop(['Date','Adj_Close'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.812500</td>\n",
       "      <td>4.156250</td>\n",
       "      <td>3.812500</td>\n",
       "      <td>4.125000</td>\n",
       "      <td>3675600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.125000</td>\n",
       "      <td>4.125000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.015625</td>\n",
       "      <td>1077600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.031250</td>\n",
       "      <td>3.953125</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>437200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.843750</td>\n",
       "      <td>3.843750</td>\n",
       "      <td>1883600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.734375</td>\n",
       "      <td>3.734375</td>\n",
       "      <td>3.390625</td>\n",
       "      <td>3.390625</td>\n",
       "      <td>7931600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Open      High       Low     Close   Volume\n",
       "0  3.812500  4.156250  3.812500  4.125000  3675600\n",
       "1  4.125000  4.125000  4.000000  4.015625  1077600\n",
       "2  4.000000  4.031250  3.953125  4.000000   437200\n",
       "3  4.000000  4.000000  3.843750  3.843750  1883600\n",
       "4  3.734375  3.734375  3.390625  3.390625  7931600"
      ]
     },
     "execution_count": 697,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Df = df.to_csv('updated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Df = pd.read_csv('updated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Df=Df.drop(['Unnamed: 0'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = Df['Close'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4392,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  4.125   ,   4.015625,   4.      , ..., 112.230003, 112.339996,\n",
       "       113.190002])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del Df['Close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4392, 4)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.812500</td>\n",
       "      <td>4.156250</td>\n",
       "      <td>3.812500</td>\n",
       "      <td>3675600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.125000</td>\n",
       "      <td>4.125000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1077600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.031250</td>\n",
       "      <td>3.953125</td>\n",
       "      <td>437200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.843750</td>\n",
       "      <td>1883600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.734375</td>\n",
       "      <td>3.734375</td>\n",
       "      <td>3.390625</td>\n",
       "      <td>7931600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Open      High       Low   Volume\n",
       "0  3.812500  4.156250  3.812500  3675600\n",
       "1  4.125000  4.125000  4.000000  1077600\n",
       "2  4.000000  4.031250  3.953125   437200\n",
       "3  4.000000  4.000000  3.843750  1883600\n",
       "4  3.734375  3.734375  3.390625  7931600"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Encode a numeric column as zscores\n",
    "def encode_numeric_zscore(df, name, mean=None, sd=None):\n",
    "    if mean is None:\n",
    "        mean = df[name].mean()\n",
    "\n",
    "    if sd is None:\n",
    "        sd = df[name].std()\n",
    "\n",
    "    df[name] = (df[name] - mean) / sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "Df['Open']= zscore(Df['Open'])\n",
    "Df['Volume'] = zscore(Df['Volume'])\n",
    "Df['High'] = zscore(Df['High'])\n",
    "Df['Low'] = zscore(Df['Low'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4392 entries, 0 to 4391\n",
      "Data columns (total 4 columns):\n",
      "Open      4392 non-null float64\n",
      "High      4392 non-null float64\n",
      "Low       4392 non-null float64\n",
      "Volume    4392 non-null float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 137.3 KB\n"
     ]
    }
   ],
   "source": [
    "Df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = Df.as_matrix(columns=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4392, 4)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4392,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.89431058, -0.88512247, -0.89240801,  1.10493783],\n",
       "       [-0.88386304, -0.88615698, -0.8860762 , -0.49735731],\n",
       "       [-0.88804206, -0.88926051, -0.88765915, -0.89231874],\n",
       "       ...,\n",
       "       [ 2.7236301 ,  2.70119294,  2.70194906,  0.15583391],\n",
       "       [ 2.73800591,  2.71476585,  2.76104594, -0.39004424],\n",
       "       [ 2.73265691,  2.77733298,  2.76138371, -0.16795552]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(x,y,test_size=0.30,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3074, 4)\n",
      "(1318, 4)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3074,)\n",
      "(1318,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Train on 3074 samples, validate on 1318 samples\n",
      "Epoch 1/1000\n",
      " - 1s - loss: 906.5053 - val_loss: 77.5468\n",
      "Epoch 2/1000\n",
      " - 0s - loss: 47.3791 - val_loss: 11.4192\n",
      "Epoch 3/1000\n",
      " - 1s - loss: 21.5368 - val_loss: 1.6890\n",
      "Epoch 4/1000\n",
      " - 0s - loss: 18.7585 - val_loss: 1.1224\n",
      "Epoch 5/1000\n",
      " - 0s - loss: 17.9746 - val_loss: 1.6922\n",
      "Epoch 6/1000\n",
      " - 0s - loss: 16.2421 - val_loss: 1.1377\n",
      "Epoch 7/1000\n",
      " - 0s - loss: 15.8791 - val_loss: 0.7579\n",
      "Epoch 8/1000\n",
      " - 0s - loss: 15.1346 - val_loss: 0.3755\n",
      "Epoch 9/1000\n",
      " - 1s - loss: 15.3064 - val_loss: 0.3843\n",
      "Epoch 10/1000\n",
      " - 0s - loss: 14.1548 - val_loss: 1.1636\n",
      "Epoch 11/1000\n",
      " - 0s - loss: 15.8102 - val_loss: 1.2888\n",
      "Epoch 12/1000\n",
      " - 0s - loss: 14.4612 - val_loss: 2.7949\n",
      "Epoch 13/1000\n",
      " - 0s - loss: 16.3884 - val_loss: 0.5618\n",
      "Epoch 00013: early stopping\n",
      "1\n",
      "Train on 3074 samples, validate on 1318 samples\n",
      "Epoch 1/1000\n",
      " - 1s - loss: 757.6232 - val_loss: 85.5084\n",
      "Epoch 2/1000\n",
      " - 0s - loss: 51.7290 - val_loss: 15.7035\n",
      "Epoch 3/1000\n",
      " - 0s - loss: 19.4238 - val_loss: 3.7693\n",
      "Epoch 4/1000\n",
      " - 0s - loss: 14.4982 - val_loss: 6.2498\n",
      "Epoch 5/1000\n",
      " - 0s - loss: 14.9716 - val_loss: 2.3368\n",
      "Epoch 6/1000\n",
      " - 0s - loss: 13.4091 - val_loss: 1.1987\n",
      "Epoch 7/1000\n",
      " - 0s - loss: 14.4215 - val_loss: 4.5324\n",
      "Epoch 8/1000\n",
      " - 0s - loss: 15.4867 - val_loss: 2.5578\n",
      "Epoch 9/1000\n",
      " - 0s - loss: 13.5707 - val_loss: 2.1879\n",
      "Epoch 10/1000\n",
      " - 0s - loss: 14.8574 - val_loss: 0.8992\n",
      "Epoch 11/1000\n",
      " - 0s - loss: 13.5043 - val_loss: 1.7215\n",
      "Epoch 12/1000\n",
      " - 0s - loss: 12.0756 - val_loss: 1.8912\n",
      "Epoch 13/1000\n",
      " - 1s - loss: 13.7425 - val_loss: 0.5102\n",
      "Epoch 14/1000\n",
      " - 0s - loss: 12.8545 - val_loss: 0.6049\n",
      "Epoch 15/1000\n",
      " - 0s - loss: 13.9450 - val_loss: 0.7504\n",
      "Epoch 16/1000\n",
      " - 1s - loss: 12.9810 - val_loss: 0.2750\n",
      "Epoch 17/1000\n",
      " - 0s - loss: 11.7117 - val_loss: 0.4387\n",
      "Epoch 18/1000\n",
      " - 1s - loss: 12.8046 - val_loss: 1.9321\n",
      "Epoch 19/1000\n",
      " - 0s - loss: 12.9345 - val_loss: 0.6671\n",
      "Epoch 20/1000\n",
      " - 0s - loss: 13.4758 - val_loss: 0.3181\n",
      "Epoch 21/1000\n",
      " - 0s - loss: 11.9992 - val_loss: 0.2895\n",
      "Epoch 00021: early stopping\n",
      "2\n",
      "Train on 3074 samples, validate on 1318 samples\n",
      "Epoch 1/1000\n",
      " - 2s - loss: 826.6459 - val_loss: 87.4089\n",
      "Epoch 2/1000\n",
      " - 0s - loss: 54.3746 - val_loss: 14.9595\n",
      "Epoch 3/1000\n",
      " - 0s - loss: 23.9280 - val_loss: 2.7135\n",
      "Epoch 4/1000\n",
      " - 1s - loss: 17.4774 - val_loss: 1.4067\n",
      "Epoch 5/1000\n",
      " - 0s - loss: 17.3632 - val_loss: 0.6620\n",
      "Epoch 6/1000\n",
      " - 0s - loss: 17.3241 - val_loss: 4.2479\n",
      "Epoch 7/1000\n",
      " - 0s - loss: 17.0820 - val_loss: 0.5959\n",
      "Epoch 8/1000\n",
      " - 0s - loss: 16.7494 - val_loss: 1.0622\n",
      "Epoch 9/1000\n",
      " - 1s - loss: 15.9872 - val_loss: 0.6735\n",
      "Epoch 10/1000\n",
      " - 0s - loss: 14.0618 - val_loss: 0.7799\n",
      "Epoch 11/1000\n",
      " - 0s - loss: 15.2156 - val_loss: 0.4104\n",
      "Epoch 12/1000\n",
      " - 0s - loss: 14.1289 - val_loss: 0.6295\n",
      "Epoch 13/1000\n",
      " - 0s - loss: 14.3303 - val_loss: 0.3598\n",
      "Epoch 14/1000\n",
      " - 0s - loss: 14.5450 - val_loss: 0.3068\n",
      "Epoch 15/1000\n",
      " - 0s - loss: 15.4589 - val_loss: 1.1069\n",
      "Epoch 16/1000\n",
      " - 0s - loss: 15.8136 - val_loss: 0.5726\n",
      "Epoch 17/1000\n",
      " - 0s - loss: 13.7749 - val_loss: 0.4883\n",
      "Epoch 18/1000\n",
      " - 0s - loss: 15.6114 - val_loss: 0.6429\n",
      "Epoch 19/1000\n",
      " - 0s - loss: 13.7241 - val_loss: 0.9365\n",
      "Epoch 00019: early stopping\n",
      "3\n",
      "Train on 3074 samples, validate on 1318 samples\n",
      "Epoch 1/1000\n",
      " - 2s - loss: 786.0345 - val_loss: 87.9529\n",
      "Epoch 2/1000\n",
      " - 0s - loss: 51.8400 - val_loss: 17.0281\n",
      "Epoch 3/1000\n",
      " - 0s - loss: 23.3917 - val_loss: 2.6525\n",
      "Epoch 4/1000\n",
      " - 0s - loss: 18.0626 - val_loss: 1.1068\n",
      "Epoch 5/1000\n",
      " - 0s - loss: 16.2291 - val_loss: 0.8580\n",
      "Epoch 6/1000\n",
      " - 0s - loss: 15.6858 - val_loss: 1.3600\n",
      "Epoch 7/1000\n",
      " - 0s - loss: 16.5478 - val_loss: 1.3563\n",
      "Epoch 8/1000\n",
      " - 0s - loss: 15.1571 - val_loss: 6.7825\n",
      "Epoch 9/1000\n",
      " - 0s - loss: 13.9351 - val_loss: 1.1013\n",
      "Epoch 10/1000\n",
      " - 0s - loss: 15.0042 - val_loss: 3.5898\n",
      "Epoch 00010: early stopping\n",
      "4\n",
      "Train on 3074 samples, validate on 1318 samples\n",
      "Epoch 1/1000\n",
      " - 2s - loss: 737.3330 - val_loss: 100.1838\n",
      "Epoch 2/1000\n",
      " - 1s - loss: 49.2868 - val_loss: 15.9369\n",
      "Epoch 3/1000\n",
      " - 1s - loss: 19.4577 - val_loss: 3.0789\n",
      "Epoch 4/1000\n",
      " - 0s - loss: 16.4985 - val_loss: 0.9976\n",
      "Epoch 5/1000\n",
      " - 0s - loss: 15.5839 - val_loss: 1.3883\n",
      "Epoch 6/1000\n",
      " - 0s - loss: 16.7111 - val_loss: 0.9980\n",
      "Epoch 7/1000\n",
      " - 0s - loss: 14.0516 - val_loss: 0.5263\n",
      "Epoch 8/1000\n",
      " - 0s - loss: 14.3707 - val_loss: 0.4491\n",
      "Epoch 9/1000\n",
      " - 0s - loss: 14.3386 - val_loss: 0.2909\n",
      "Epoch 10/1000\n",
      " - 0s - loss: 13.2808 - val_loss: 1.2280\n",
      "Epoch 11/1000\n",
      " - 0s - loss: 14.1599 - val_loss: 0.4103\n",
      "Epoch 12/1000\n",
      " - 0s - loss: 12.6963 - val_loss: 1.6995\n",
      "Epoch 13/1000\n",
      " - 0s - loss: 13.9328 - val_loss: 0.8876\n",
      "Epoch 14/1000\n",
      " - 0s - loss: 13.2413 - val_loss: 0.5979\n",
      "Epoch 00014: early stopping\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath=r\"G:\\215\\network_best.hdf5\", verbose=0, save_best_only=True) # save best model\n",
    "\n",
    "for i in range(5):\n",
    "    print(i)\n",
    "    model_regression= Sequential()\n",
    "    model_regression.add(Dense(150,input_dim=X_train.shape[1], activation='relu')) # Hidden 1     #  why input_dim=x.shape[1]?  \n",
    "    model_regression.add(Dropout(0.10))\n",
    "    model_regression.add(Dense(100,activation='relu')) # Hidden 2\n",
    "    model_regression.add(Dropout(0.10))\n",
    "    model_regression.add(Dense(50,activation='relu'))\n",
    "    model_regression.add(Dropout(0.10))\n",
    "    model_regression.add(Dense(1))\n",
    "    \n",
    "    #model_regression.add(Dense(y_train.shape[2],activation='softmax')) # Output\n",
    "    model_regression.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=5, verbose=1, mode='auto')\n",
    "    \n",
    "    model_regression.fit(X_train, y_train,validation_data=(X_test,y_test),callbacks=[monitor,checkpointer],verbose=2,epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Plot a confusion matrix.\n",
    "# cm is the confusion matrix, names are the names of the classes.\n",
    "def plot_confusion_matrix(cm, names, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(names))\n",
    "    plt.xticks(tick_marks, names, rotation=45)\n",
    "    plt.yticks(tick_marks, names)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "\n",
    "# Plot an ROC. pred - the predictions, y - the expected output.\n",
    "def plot_roc(pred,y):\n",
    "    fpr, tpr, thresholds = roc_curve(y, pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC)')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (MSE): 0.2750389107898059\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "model_regression.load_weights(r\"G:\\215\\network_best.hdf5\")\n",
    "\n",
    "pred = model_regression.predict(X_test)\n",
    "\n",
    "score = metrics.mean_squared_error(pred,y_test)\n",
    "print(\"Final score (MSE): {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 0.5244415227552124\n"
     ]
    }
   ],
   "source": [
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "print(\"Final score (RMSE): {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAD8CAYAAABthzNFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nbVAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d06f225b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "# Regression chart.\n",
    "def chart_regression(pred,y,sort=True):\n",
    "    t = pd.DataFrame({'pred' : pred, 'y' : y.flatten()})\n",
    "    if sort:\n",
    "        t.sort_values(by=['y'],inplace=True)\n",
    "    a = plt.plot(t['y'].tolist(),label='expected')\n",
    "    b = plt.plot(t['pred'].tolist(),label='prediction')\n",
    "    plt.ylabel('output')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "# Plot the chart\n",
    "chart_regression(pred.flatten(),y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "regression model 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Train on 3074 samples, validate on 1318 samples\n",
      "Epoch 1/1000\n",
      " - 2s - loss: 542.5270 - val_loss: 73.9681\n",
      "Epoch 2/1000\n",
      " - 0s - loss: 36.9989 - val_loss: 20.8023\n",
      "Epoch 3/1000\n",
      " - 0s - loss: 22.5710 - val_loss: 4.1842\n",
      "Epoch 4/1000\n",
      " - 0s - loss: 18.2938 - val_loss: 4.3392\n",
      "Epoch 5/1000\n",
      " - 0s - loss: 19.1219 - val_loss: 0.6178\n",
      "Epoch 6/1000\n",
      " - 0s - loss: 18.0382 - val_loss: 0.3804\n",
      "Epoch 7/1000\n",
      " - 0s - loss: 15.3097 - val_loss: 27.2881\n",
      "Epoch 8/1000\n",
      " - 0s - loss: 17.0468 - val_loss: 1.4658\n",
      "Epoch 9/1000\n",
      " - 0s - loss: 17.7063 - val_loss: 28.4276\n",
      "Epoch 10/1000\n",
      " - 1s - loss: 16.5170 - val_loss: 0.9247\n",
      "Epoch 11/1000\n",
      " - 0s - loss: 15.7117 - val_loss: 1.6654\n",
      "Epoch 00011: early stopping\n",
      "1\n",
      "Train on 3074 samples, validate on 1318 samples\n",
      "Epoch 1/1000\n",
      " - 2s - loss: 554.9243 - val_loss: 75.4472\n",
      "Epoch 2/1000\n",
      " - 0s - loss: 39.4370 - val_loss: 8.8361\n",
      "Epoch 3/1000\n",
      " - 0s - loss: 20.5940 - val_loss: 4.8036\n",
      "Epoch 4/1000\n",
      " - 0s - loss: 18.8380 - val_loss: 4.7637\n",
      "Epoch 5/1000\n",
      " - 0s - loss: 17.6289 - val_loss: 2.1750\n",
      "Epoch 6/1000\n",
      " - 0s - loss: 16.3755 - val_loss: 2.7196\n",
      "Epoch 7/1000\n",
      " - 0s - loss: 16.9096 - val_loss: 12.0240\n",
      "Epoch 8/1000\n",
      " - 1s - loss: 16.8684 - val_loss: 4.9106\n",
      "Epoch 9/1000\n",
      " - 0s - loss: 17.5941 - val_loss: 1.5842\n",
      "Epoch 10/1000\n",
      " - 0s - loss: 18.9639 - val_loss: 4.8280\n",
      "Epoch 11/1000\n",
      " - 0s - loss: 16.4801 - val_loss: 4.2677\n",
      "Epoch 12/1000\n",
      " - 0s - loss: 16.0299 - val_loss: 0.6795\n",
      "Epoch 13/1000\n",
      " - 0s - loss: 16.3372 - val_loss: 1.5887\n",
      "Epoch 14/1000\n",
      " - 0s - loss: 16.1798 - val_loss: 2.7473\n",
      "Epoch 15/1000\n",
      " - 0s - loss: 16.9777 - val_loss: 0.3675\n",
      "Epoch 16/1000\n",
      " - 0s - loss: 15.3904 - val_loss: 3.2396\n",
      "Epoch 17/1000\n",
      " - 0s - loss: 15.5713 - val_loss: 41.9538\n",
      "Epoch 18/1000\n",
      " - 0s - loss: 14.6123 - val_loss: 0.4547\n",
      "Epoch 19/1000\n",
      " - 0s - loss: 15.9926 - val_loss: 0.7033\n",
      "Epoch 20/1000\n",
      " - 1s - loss: 15.8923 - val_loss: 10.4473\n",
      "Epoch 00020: early stopping\n",
      "2\n",
      "Train on 3074 samples, validate on 1318 samples\n",
      "Epoch 1/1000\n",
      " - 2s - loss: 546.4782 - val_loss: 52.7655\n",
      "Epoch 2/1000\n",
      " - 1s - loss: 32.2090 - val_loss: 23.0237\n",
      "Epoch 3/1000\n",
      " - 0s - loss: 19.2497 - val_loss: 23.2963\n",
      "Epoch 4/1000\n",
      " - 0s - loss: 18.6782 - val_loss: 1.8363\n",
      "Epoch 5/1000\n",
      " - 1s - loss: 17.9713 - val_loss: 3.7148\n",
      "Epoch 6/1000\n",
      " - 1s - loss: 17.5086 - val_loss: 5.7796\n",
      "Epoch 7/1000\n",
      " - 1s - loss: 17.8715 - val_loss: 16.1162\n",
      "Epoch 8/1000\n",
      " - 0s - loss: 16.2340 - val_loss: 11.5534\n",
      "Epoch 9/1000\n",
      " - 0s - loss: 16.6017 - val_loss: 1.2203\n",
      "Epoch 10/1000\n",
      " - 0s - loss: 15.3901 - val_loss: 1.5314\n",
      "Epoch 11/1000\n",
      " - 1s - loss: 15.2526 - val_loss: 0.7649\n",
      "Epoch 12/1000\n",
      " - 1s - loss: 14.3938 - val_loss: 1.0499\n",
      "Epoch 13/1000\n",
      " - 0s - loss: 14.3627 - val_loss: 27.4620\n",
      "Epoch 14/1000\n",
      " - 0s - loss: 14.2270 - val_loss: 3.4100\n",
      "Epoch 15/1000\n",
      " - 0s - loss: 14.0983 - val_loss: 0.8714\n",
      "Epoch 16/1000\n",
      " - 0s - loss: 15.3180 - val_loss: 4.5396\n",
      "Epoch 00016: early stopping\n",
      "3\n",
      "Train on 3074 samples, validate on 1318 samples\n",
      "Epoch 1/1000\n",
      " - 2s - loss: 488.3502 - val_loss: 57.6930\n",
      "Epoch 2/1000\n",
      " - 0s - loss: 29.7990 - val_loss: 11.9989\n",
      "Epoch 3/1000\n",
      " - 0s - loss: 16.1760 - val_loss: 2.6355\n",
      "Epoch 4/1000\n",
      " - 0s - loss: 15.7421 - val_loss: 7.9788\n",
      "Epoch 5/1000\n",
      " - 0s - loss: 15.5031 - val_loss: 1.9778\n",
      "Epoch 6/1000\n",
      " - 0s - loss: 13.6868 - val_loss: 1.0300\n",
      "Epoch 7/1000\n",
      " - 0s - loss: 14.7534 - val_loss: 13.5903\n",
      "Epoch 8/1000\n",
      " - 0s - loss: 12.7700 - val_loss: 1.0769\n",
      "Epoch 9/1000\n",
      " - 0s - loss: 12.9746 - val_loss: 1.3288\n",
      "Epoch 10/1000\n",
      " - 0s - loss: 14.9289 - val_loss: 6.9912\n",
      "Epoch 11/1000\n",
      " - 0s - loss: 13.0788 - val_loss: 1.0985\n",
      "Epoch 00011: early stopping\n",
      "4\n",
      "Train on 3074 samples, validate on 1318 samples\n",
      "Epoch 1/1000\n",
      " - 2s - loss: 516.8681 - val_loss: 67.1609\n",
      "Epoch 2/1000\n",
      " - 0s - loss: 35.7972 - val_loss: 12.2897\n",
      "Epoch 3/1000\n",
      " - 0s - loss: 17.0354 - val_loss: 30.7502\n",
      "Epoch 4/1000\n",
      " - 0s - loss: 15.8637 - val_loss: 1.5999\n",
      "Epoch 5/1000\n",
      " - 0s - loss: 15.0617 - val_loss: 14.5639\n",
      "Epoch 6/1000\n",
      " - 0s - loss: 14.4600 - val_loss: 2.0401\n",
      "Epoch 7/1000\n",
      " - 0s - loss: 15.2650 - val_loss: 30.1841\n",
      "Epoch 8/1000\n",
      " - 0s - loss: 15.9481 - val_loss: 2.7716\n",
      "Epoch 9/1000\n",
      " - 0s - loss: 14.3781 - val_loss: 5.6637\n",
      "Epoch 00009: early stopping\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath=r\"G:\\215\\network_best1.hdf5\", verbose=0, save_best_only=True) # save best model\n",
    "\n",
    "for i in range(5):\n",
    "    print(i)\n",
    "    model_regression= Sequential()\n",
    "    model_regression.add(Dense(150,input_dim=X_train.shape[1], activation='relu')) # Hidden 1     #  why input_dim=x.shape[1]?  \n",
    "    model_regression.add(Dropout(0.10))\n",
    "    model_regression.add(Dense(100,activation='relu')) # Hidden 2\n",
    "    model_regression.add(Dropout(0.10))\n",
    "    model_regression.add(Dense(50,activation='relu'))\n",
    "    model_regression.add(Dropout(0.10))\n",
    "    model_regression.add(Dense(1))\n",
    "    \n",
    "    #model_regression.add(Dense(y_train.shape[2],activation='softmax')) # Output\n",
    "    model_regression.compile(loss='mean_squared_error', optimizer='rmsprop')\n",
    "\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=5, verbose=1, mode='auto')\n",
    "    \n",
    "    model_regression.fit(X_train, y_train,validation_data=(X_test,y_test),callbacks=[monitor,checkpointer],verbose=2,epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (MSE): 0.3675435253554791\n",
      "Final score (RMSE): 0.6062536806943766\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "model_regression.load_weights(r\"G:\\215\\network_best1.hdf5\")\n",
    "\n",
    "pred = model_regression.predict(X_test)\n",
    "\n",
    "score = metrics.mean_squared_error(pred,y_test)\n",
    "print(\"Final score (MSE): {}\".format(score))\n",
    "\n",
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "print(\"Final score (RMSE): {}\".format(score))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "regression model 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Train on 3074 samples, validate on 1318 samples\n",
      "Epoch 1/1000\n",
      " - 2s - loss: 1402.7783 - val_loss: 1171.3341\n",
      "Epoch 2/1000\n",
      " - 0s - loss: 1054.3987 - val_loss: 992.0418\n",
      "Epoch 3/1000\n",
      " - 0s - loss: 900.9249 - val_loss: 854.0272\n",
      "Epoch 4/1000\n",
      " - 0s - loss: 780.0408 - val_loss: 741.2020\n",
      "Epoch 5/1000\n",
      " - 0s - loss: 672.9926 - val_loss: 645.2374\n",
      "Epoch 6/1000\n",
      " - 0s - loss: 587.2379 - val_loss: 568.5444\n",
      "Epoch 7/1000\n",
      " - 0s - loss: 519.5083 - val_loss: 502.5167\n",
      "Epoch 8/1000\n",
      " - 0s - loss: 460.0988 - val_loss: 445.3285\n",
      "Epoch 9/1000\n",
      " - 0s - loss: 407.8604 - val_loss: 398.6894\n",
      "Epoch 10/1000\n",
      " - 0s - loss: 365.7998 - val_loss: 357.2599\n",
      "Epoch 11/1000\n",
      " - 0s - loss: 327.8897 - val_loss: 319.0841\n",
      "Epoch 12/1000\n",
      " - 0s - loss: 294.6554 - val_loss: 284.3711\n",
      "Epoch 13/1000\n",
      " - 0s - loss: 263.5725 - val_loss: 253.6327\n",
      "Epoch 14/1000\n",
      " - 0s - loss: 238.2795 - val_loss: 227.2414\n",
      "Epoch 15/1000\n",
      " - 0s - loss: 214.2707 - val_loss: 204.1190\n",
      "Epoch 16/1000\n",
      " - 0s - loss: 193.3602 - val_loss: 182.9158\n",
      "Epoch 17/1000\n",
      " - 0s - loss: 175.9765 - val_loss: 162.7350\n",
      "Epoch 18/1000\n",
      " - 0s - loss: 155.8913 - val_loss: 146.1156\n",
      "Epoch 19/1000\n",
      " - 0s - loss: 143.0363 - val_loss: 131.4375\n",
      "Epoch 20/1000\n",
      " - 0s - loss: 127.7639 - val_loss: 118.3562\n",
      "Epoch 21/1000\n",
      " - 0s - loss: 118.8678 - val_loss: 105.5026\n",
      "Epoch 22/1000\n",
      " - 0s - loss: 104.7866 - val_loss: 95.3013\n",
      "Epoch 23/1000\n",
      " - 0s - loss: 98.6289 - val_loss: 86.3860\n",
      "Epoch 24/1000\n",
      " - 0s - loss: 89.8988 - val_loss: 77.7175\n",
      "Epoch 25/1000\n",
      " - 0s - loss: 81.2540 - val_loss: 68.2260\n",
      "Epoch 26/1000\n",
      " - 0s - loss: 76.0774 - val_loss: 61.0504\n",
      "Epoch 27/1000\n",
      " - 0s - loss: 68.2644 - val_loss: 55.3724\n",
      "Epoch 28/1000\n",
      " - 0s - loss: 63.9965 - val_loss: 49.9369\n",
      "Epoch 29/1000\n",
      " - 0s - loss: 59.7699 - val_loss: 45.1803\n",
      "Epoch 30/1000\n",
      " - 0s - loss: 55.8322 - val_loss: 40.3815\n",
      "Epoch 31/1000\n",
      " - 0s - loss: 52.0329 - val_loss: 35.5341\n",
      "Epoch 32/1000\n",
      " - 0s - loss: 49.3527 - val_loss: 37.8529\n",
      "Epoch 33/1000\n",
      " - 0s - loss: 46.6313 - val_loss: 30.1804\n",
      "Epoch 34/1000\n",
      " - 0s - loss: 43.0157 - val_loss: 28.0368\n",
      "Epoch 35/1000\n",
      " - 0s - loss: 40.5150 - val_loss: 29.1185\n",
      "Epoch 36/1000\n",
      " - 0s - loss: 37.3714 - val_loss: 22.5112\n",
      "Epoch 37/1000\n",
      " - 0s - loss: 37.1202 - val_loss: 20.2642\n",
      "Epoch 38/1000\n",
      " - 0s - loss: 34.6800 - val_loss: 19.6365\n",
      "Epoch 39/1000\n",
      " - 0s - loss: 33.8198 - val_loss: 16.3057\n",
      "Epoch 40/1000\n",
      " - 0s - loss: 32.1530 - val_loss: 14.9645\n",
      "Epoch 41/1000\n",
      " - 0s - loss: 31.6425 - val_loss: 13.5865\n",
      "Epoch 42/1000\n",
      " - 0s - loss: 30.2658 - val_loss: 16.0050\n",
      "Epoch 43/1000\n",
      " - 0s - loss: 30.3396 - val_loss: 15.5276\n",
      "Epoch 44/1000\n",
      " - 0s - loss: 28.2105 - val_loss: 10.9034\n",
      "Epoch 45/1000\n",
      " - 0s - loss: 26.7443 - val_loss: 13.0571\n",
      "Epoch 46/1000\n",
      " - 0s - loss: 25.6564 - val_loss: 9.0816\n",
      "Epoch 47/1000\n",
      " - 0s - loss: 25.9822 - val_loss: 8.7230\n",
      "Epoch 48/1000\n",
      " - 0s - loss: 26.2856 - val_loss: 11.7063\n",
      "Epoch 49/1000\n",
      " - 0s - loss: 24.2377 - val_loss: 8.5702\n",
      "Epoch 50/1000\n",
      " - 0s - loss: 25.0359 - val_loss: 6.6557\n",
      "Epoch 51/1000\n",
      " - 0s - loss: 23.5382 - val_loss: 9.2356\n",
      "Epoch 52/1000\n",
      " - 0s - loss: 22.2827 - val_loss: 5.6444\n",
      "Epoch 53/1000\n",
      " - 0s - loss: 23.4239 - val_loss: 7.0043\n",
      "Epoch 54/1000\n",
      " - 0s - loss: 22.0568 - val_loss: 8.1201\n",
      "Epoch 55/1000\n",
      " - 0s - loss: 22.5779 - val_loss: 5.9946\n",
      "Epoch 56/1000\n",
      " - 0s - loss: 21.5711 - val_loss: 5.8186\n",
      "Epoch 57/1000\n",
      " - 0s - loss: 20.3690 - val_loss: 8.0072\n",
      "Epoch 00057: early stopping\n",
      "1\n",
      "Train on 3074 samples, validate on 1318 samples\n",
      "Epoch 1/1000\n",
      " - 2s - loss: 1408.8562 - val_loss: 1181.8966\n",
      "Epoch 2/1000\n",
      " - 0s - loss: 1065.2394 - val_loss: 999.0025\n",
      "Epoch 3/1000\n",
      " - 0s - loss: 908.3334 - val_loss: 860.4767\n",
      "Epoch 4/1000\n",
      " - 0s - loss: 782.5787 - val_loss: 746.8260\n",
      "Epoch 5/1000\n",
      " - 0s - loss: 678.5232 - val_loss: 649.4315\n",
      "Epoch 6/1000\n",
      " - 1s - loss: 589.7572 - val_loss: 572.1888\n",
      "Epoch 7/1000\n",
      " - 0s - loss: 519.4513 - val_loss: 505.9502\n",
      "Epoch 8/1000\n",
      " - 1s - loss: 466.5766 - val_loss: 451.3276\n",
      "Epoch 9/1000\n",
      " - 0s - loss: 414.4071 - val_loss: 405.4303\n",
      "Epoch 10/1000\n",
      " - 0s - loss: 366.4827 - val_loss: 358.9358\n",
      "Epoch 11/1000\n",
      " - 1s - loss: 331.6107 - val_loss: 321.7164\n",
      "Epoch 12/1000\n",
      " - 0s - loss: 296.1830 - val_loss: 286.3834\n",
      "Epoch 13/1000\n",
      " - 0s - loss: 267.7680 - val_loss: 256.8670\n",
      "Epoch 14/1000\n",
      " - 0s - loss: 239.5855 - val_loss: 228.4895\n",
      "Epoch 15/1000\n",
      " - 1s - loss: 213.6259 - val_loss: 204.7224\n",
      "Epoch 16/1000\n",
      " - 1s - loss: 194.8499 - val_loss: 183.6824\n",
      "Epoch 17/1000\n",
      " - 0s - loss: 172.7380 - val_loss: 163.5634\n",
      "Epoch 18/1000\n",
      " - 1s - loss: 159.2164 - val_loss: 148.6503\n",
      "Epoch 19/1000\n",
      " - 0s - loss: 141.3436 - val_loss: 132.0616\n",
      "Epoch 20/1000\n",
      " - 1s - loss: 130.0586 - val_loss: 118.7836\n",
      "Epoch 21/1000\n",
      " - 1s - loss: 116.2617 - val_loss: 107.1494\n",
      "Epoch 22/1000\n",
      " - 0s - loss: 107.3169 - val_loss: 96.0154\n",
      "Epoch 23/1000\n",
      " - 0s - loss: 97.7371 - val_loss: 86.2045\n",
      "Epoch 24/1000\n",
      " - 0s - loss: 90.6936 - val_loss: 82.3897\n",
      "Epoch 25/1000\n",
      " - 0s - loss: 88.1782 - val_loss: 69.6773\n",
      "Epoch 26/1000\n",
      " - 1s - loss: 76.3547 - val_loss: 65.3350\n",
      "Epoch 27/1000\n",
      " - 1s - loss: 71.5387 - val_loss: 61.4775\n",
      "Epoch 28/1000\n",
      " - 1s - loss: 68.0080 - val_loss: 53.2481\n",
      "Epoch 29/1000\n",
      " - 0s - loss: 59.8821 - val_loss: 44.6844\n",
      "Epoch 30/1000\n",
      " - 1s - loss: 54.6632 - val_loss: 40.9827\n",
      "Epoch 31/1000\n",
      " - 0s - loss: 50.0775 - val_loss: 36.0495\n",
      "Epoch 32/1000\n",
      " - 0s - loss: 48.2596 - val_loss: 33.6409\n",
      "Epoch 33/1000\n",
      " - 0s - loss: 42.8420 - val_loss: 30.3524\n",
      "Epoch 34/1000\n",
      " - 0s - loss: 43.2754 - val_loss: 28.6109\n",
      "Epoch 35/1000\n",
      " - 0s - loss: 39.0762 - val_loss: 28.3229\n",
      "Epoch 36/1000\n",
      " - 0s - loss: 39.7374 - val_loss: 23.3239\n",
      "Epoch 37/1000\n",
      " - 0s - loss: 37.6308 - val_loss: 19.4917\n",
      "Epoch 38/1000\n",
      " - 0s - loss: 34.8651 - val_loss: 17.7396\n",
      "Epoch 39/1000\n",
      " - 0s - loss: 33.8965 - val_loss: 22.2445\n",
      "Epoch 40/1000\n",
      " - 0s - loss: 31.4011 - val_loss: 15.9899\n",
      "Epoch 41/1000\n",
      " - 0s - loss: 33.9811 - val_loss: 14.8510\n",
      "Epoch 42/1000\n",
      " - 0s - loss: 29.8020 - val_loss: 12.3083\n",
      "Epoch 43/1000\n",
      " - 0s - loss: 28.1036 - val_loss: 11.6527\n",
      "Epoch 44/1000\n",
      " - 0s - loss: 28.1818 - val_loss: 12.0790\n",
      "Epoch 45/1000\n",
      " - 0s - loss: 28.5706 - val_loss: 11.7768\n",
      "Epoch 46/1000\n",
      " - 0s - loss: 25.7133 - val_loss: 10.0733\n",
      "Epoch 47/1000\n",
      " - 0s - loss: 25.2391 - val_loss: 9.2262\n",
      "Epoch 48/1000\n",
      " - 1s - loss: 25.3784 - val_loss: 8.3240\n",
      "Epoch 49/1000\n",
      " - 0s - loss: 23.6838 - val_loss: 7.4794\n",
      "Epoch 50/1000\n",
      " - 0s - loss: 23.5891 - val_loss: 6.2196\n",
      "Epoch 51/1000\n",
      " - 0s - loss: 22.7702 - val_loss: 8.1419\n",
      "Epoch 52/1000\n",
      " - 0s - loss: 22.5727 - val_loss: 8.4410\n",
      "Epoch 53/1000\n",
      " - 0s - loss: 24.6202 - val_loss: 4.9420\n",
      "Epoch 54/1000\n",
      " - 0s - loss: 20.8076 - val_loss: 4.7618\n",
      "Epoch 55/1000\n",
      " - 0s - loss: 21.4180 - val_loss: 10.7174\n",
      "Epoch 56/1000\n",
      " - 0s - loss: 21.0035 - val_loss: 10.0915\n",
      "Epoch 57/1000\n",
      " - 0s - loss: 23.9267 - val_loss: 7.9617\n",
      "Epoch 58/1000\n",
      " - 0s - loss: 19.8530 - val_loss: 3.4714\n",
      "Epoch 59/1000\n",
      " - 0s - loss: 19.9914 - val_loss: 4.6984\n",
      "Epoch 60/1000\n",
      " - 0s - loss: 20.6984 - val_loss: 7.7946\n",
      "Epoch 61/1000\n",
      " - 0s - loss: 21.3518 - val_loss: 3.4748\n",
      "Epoch 62/1000\n",
      " - 0s - loss: 19.0775 - val_loss: 8.8139\n",
      "Epoch 63/1000\n",
      " - 1s - loss: 19.0173 - val_loss: 6.6847\n",
      "Epoch 00063: early stopping\n",
      "2\n",
      "Train on 3074 samples, validate on 1318 samples\n",
      "Epoch 1/1000\n",
      " - 3s - loss: 1447.3638 - val_loss: 1238.1459\n",
      "Epoch 2/1000\n",
      " - 0s - loss: 1115.9560 - val_loss: 1050.0212\n",
      "Epoch 3/1000\n",
      " - 0s - loss: 954.9495 - val_loss: 906.4611\n",
      "Epoch 4/1000\n",
      " - 1s - loss: 824.7502 - val_loss: 788.7453\n",
      "Epoch 5/1000\n",
      " - 0s - loss: 717.8534 - val_loss: 686.0450\n",
      "Epoch 6/1000\n",
      " - 1s - loss: 623.7790 - val_loss: 603.7685\n",
      "Epoch 7/1000\n",
      " - 0s - loss: 550.4678 - val_loss: 534.8857\n",
      "Epoch 8/1000\n",
      " - 1s - loss: 490.1759 - val_loss: 475.9352\n",
      "Epoch 9/1000\n",
      " - 0s - loss: 434.8113 - val_loss: 425.6274\n",
      "Epoch 10/1000\n",
      " - 0s - loss: 393.3474 - val_loss: 381.2015\n",
      "Epoch 11/1000\n",
      " - 0s - loss: 351.1965 - val_loss: 342.9834\n",
      "Epoch 12/1000\n",
      " - 0s - loss: 316.1434 - val_loss: 306.1127\n",
      "Epoch 13/1000\n",
      " - 0s - loss: 283.3854 - val_loss: 274.1363\n",
      "Epoch 14/1000\n",
      " - 0s - loss: 254.2527 - val_loss: 243.9335\n",
      "Epoch 15/1000\n",
      " - 0s - loss: 226.7329 - val_loss: 219.1457\n",
      "Epoch 16/1000\n",
      " - 0s - loss: 204.0405 - val_loss: 195.1686\n",
      "Epoch 17/1000\n",
      " - 0s - loss: 184.6285 - val_loss: 173.8138\n",
      "Epoch 18/1000\n",
      " - 0s - loss: 167.7798 - val_loss: 156.2306\n",
      "Epoch 19/1000\n",
      " - 0s - loss: 150.8051 - val_loss: 140.4839\n",
      "Epoch 20/1000\n",
      " - 0s - loss: 136.9188 - val_loss: 126.1513\n",
      "Epoch 21/1000\n",
      " - 0s - loss: 124.6198 - val_loss: 114.0551\n",
      "Epoch 22/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 111.9718 - val_loss: 101.9181\n",
      "Epoch 23/1000\n",
      " - 0s - loss: 104.6508 - val_loss: 92.1756\n",
      "Epoch 24/1000\n",
      " - 1s - loss: 94.5820 - val_loss: 87.1923\n",
      "Epoch 25/1000\n",
      " - 0s - loss: 86.2203 - val_loss: 74.1930\n",
      "Epoch 26/1000\n",
      " - 0s - loss: 81.6292 - val_loss: 67.3568\n",
      "Epoch 27/1000\n",
      " - 0s - loss: 73.1344 - val_loss: 60.1628\n",
      "Epoch 28/1000\n",
      " - 0s - loss: 68.1938 - val_loss: 55.4090\n",
      "Epoch 29/1000\n",
      " - 0s - loss: 63.1159 - val_loss: 50.9967\n",
      "Epoch 30/1000\n",
      " - 0s - loss: 59.5191 - val_loss: 47.9517\n",
      "Epoch 31/1000\n",
      " - 0s - loss: 56.4238 - val_loss: 39.6673\n",
      "Epoch 32/1000\n",
      " - 0s - loss: 50.4328 - val_loss: 35.4824\n",
      "Epoch 33/1000\n",
      " - 0s - loss: 51.4872 - val_loss: 32.1649\n",
      "Epoch 34/1000\n",
      " - 0s - loss: 45.3014 - val_loss: 29.2263\n",
      "Epoch 35/1000\n",
      " - 0s - loss: 41.0634 - val_loss: 26.3986\n",
      "Epoch 36/1000\n",
      " - 0s - loss: 39.1668 - val_loss: 24.1687\n",
      "Epoch 37/1000\n",
      " - 0s - loss: 38.1490 - val_loss: 23.6195\n",
      "Epoch 38/1000\n",
      " - 0s - loss: 37.1747 - val_loss: 21.7016\n",
      "Epoch 39/1000\n",
      " - 0s - loss: 35.4454 - val_loss: 19.4177\n",
      "Epoch 40/1000\n",
      " - 0s - loss: 33.5175 - val_loss: 16.0930\n",
      "Epoch 41/1000\n",
      " - 0s - loss: 32.3112 - val_loss: 15.8587\n",
      "Epoch 42/1000\n",
      " - 0s - loss: 30.2631 - val_loss: 13.7460\n",
      "Epoch 43/1000\n",
      " - 0s - loss: 30.8827 - val_loss: 13.0793\n",
      "Epoch 44/1000\n",
      " - 0s - loss: 29.8805 - val_loss: 12.6511\n",
      "Epoch 45/1000\n",
      " - 0s - loss: 29.9391 - val_loss: 9.7276\n",
      "Epoch 46/1000\n",
      " - 0s - loss: 26.9765 - val_loss: 8.8476\n",
      "Epoch 47/1000\n",
      " - 0s - loss: 27.3675 - val_loss: 11.6757\n",
      "Epoch 48/1000\n",
      " - 0s - loss: 26.9145 - val_loss: 7.6515\n",
      "Epoch 49/1000\n",
      " - 0s - loss: 24.2900 - val_loss: 6.6531\n",
      "Epoch 50/1000\n",
      " - 0s - loss: 26.1048 - val_loss: 6.9748\n",
      "Epoch 51/1000\n",
      " - 0s - loss: 25.0739 - val_loss: 10.4628\n",
      "Epoch 52/1000\n",
      " - 0s - loss: 24.8236 - val_loss: 9.4438\n",
      "Epoch 53/1000\n",
      " - 0s - loss: 24.3422 - val_loss: 5.4716\n",
      "Epoch 54/1000\n",
      " - 0s - loss: 23.0381 - val_loss: 5.1662\n",
      "Epoch 55/1000\n",
      " - 0s - loss: 21.4217 - val_loss: 6.9888\n",
      "Epoch 56/1000\n",
      " - 0s - loss: 22.6685 - val_loss: 6.0151\n",
      "Epoch 57/1000\n",
      " - 0s - loss: 25.0324 - val_loss: 4.2089\n",
      "Epoch 58/1000\n",
      " - 0s - loss: 23.1813 - val_loss: 7.6150\n",
      "Epoch 59/1000\n",
      " - 0s - loss: 23.7771 - val_loss: 3.7744\n",
      "Epoch 60/1000\n",
      " - 0s - loss: 20.2326 - val_loss: 4.8518\n",
      "Epoch 61/1000\n",
      " - 0s - loss: 20.1637 - val_loss: 4.1563\n",
      "Epoch 62/1000\n",
      " - 0s - loss: 20.8822 - val_loss: 5.1990\n",
      "Epoch 63/1000\n",
      " - 0s - loss: 20.1643 - val_loss: 3.9719\n",
      "Epoch 64/1000\n",
      " - 0s - loss: 20.5832 - val_loss: 3.2716\n",
      "Epoch 65/1000\n",
      " - 0s - loss: 18.9890 - val_loss: 2.5936\n",
      "Epoch 66/1000\n",
      " - 0s - loss: 18.4815 - val_loss: 4.4907\n",
      "Epoch 67/1000\n",
      " - 0s - loss: 19.6509 - val_loss: 3.5597\n",
      "Epoch 68/1000\n",
      " - 0s - loss: 18.3184 - val_loss: 4.4574\n",
      "Epoch 69/1000\n",
      " - 0s - loss: 20.2434 - val_loss: 3.9605\n",
      "Epoch 70/1000\n",
      " - 0s - loss: 17.8813 - val_loss: 4.2446\n",
      "Epoch 00070: early stopping\n",
      "3\n",
      "Train on 3074 samples, validate on 1318 samples\n",
      "Epoch 1/1000\n",
      " - 2s - loss: 1394.3589 - val_loss: 1167.2121\n",
      "Epoch 2/1000\n",
      " - 0s - loss: 1048.4350 - val_loss: 986.3659\n",
      "Epoch 3/1000\n",
      " - 0s - loss: 896.3793 - val_loss: 850.6314\n",
      "Epoch 4/1000\n",
      " - 0s - loss: 776.0412 - val_loss: 738.5742\n",
      "Epoch 5/1000\n",
      " - 0s - loss: 671.4626 - val_loss: 644.5604\n",
      "Epoch 6/1000\n",
      " - 0s - loss: 587.0346 - val_loss: 567.3735\n",
      "Epoch 7/1000\n",
      " - 0s - loss: 519.6706 - val_loss: 503.9918\n",
      "Epoch 8/1000\n",
      " - 0s - loss: 463.5392 - val_loss: 448.8590\n",
      "Epoch 9/1000\n",
      " - 0s - loss: 411.9556 - val_loss: 400.3798\n",
      "Epoch 10/1000\n",
      " - 0s - loss: 368.9947 - val_loss: 358.9790\n",
      "Epoch 11/1000\n",
      " - 0s - loss: 329.2225 - val_loss: 320.5090\n",
      "Epoch 12/1000\n",
      " - 0s - loss: 296.3374 - val_loss: 286.4093\n",
      "Epoch 13/1000\n",
      " - 0s - loss: 265.1028 - val_loss: 256.5398\n",
      "Epoch 14/1000\n",
      " - 0s - loss: 238.7957 - val_loss: 227.4241\n",
      "Epoch 15/1000\n",
      " - 0s - loss: 212.5597 - val_loss: 203.4633\n",
      "Epoch 16/1000\n",
      " - 0s - loss: 195.3868 - val_loss: 181.6520\n",
      "Epoch 17/1000\n",
      " - 0s - loss: 172.4608 - val_loss: 161.7491\n",
      "Epoch 18/1000\n",
      " - 0s - loss: 155.1134 - val_loss: 145.0984\n",
      "Epoch 19/1000\n",
      " - 0s - loss: 140.2641 - val_loss: 130.0657\n",
      "Epoch 20/1000\n",
      " - 0s - loss: 128.7543 - val_loss: 116.9644\n",
      "Epoch 21/1000\n",
      " - 0s - loss: 119.4321 - val_loss: 106.0077\n",
      "Epoch 22/1000\n",
      " - 0s - loss: 107.3168 - val_loss: 94.1543\n",
      "Epoch 23/1000\n",
      " - 0s - loss: 97.8189 - val_loss: 84.1868\n",
      "Epoch 24/1000\n",
      " - 0s - loss: 88.4193 - val_loss: 76.4084\n",
      "Epoch 25/1000\n",
      " - 0s - loss: 81.8962 - val_loss: 68.2431\n",
      "Epoch 26/1000\n",
      " - 0s - loss: 73.6116 - val_loss: 62.3465\n",
      "Epoch 27/1000\n",
      " - 0s - loss: 70.3314 - val_loss: 55.0753\n",
      "Epoch 28/1000\n",
      " - 0s - loss: 62.7459 - val_loss: 49.4864\n",
      "Epoch 29/1000\n",
      " - 0s - loss: 57.2056 - val_loss: 47.8792\n",
      "Epoch 30/1000\n",
      " - 0s - loss: 55.2464 - val_loss: 40.4667\n",
      "Epoch 31/1000\n",
      " - 0s - loss: 50.8751 - val_loss: 36.8444\n",
      "Epoch 32/1000\n",
      " - 0s - loss: 48.0547 - val_loss: 33.4824\n",
      "Epoch 33/1000\n",
      " - 0s - loss: 44.5689 - val_loss: 30.1490\n",
      "Epoch 34/1000\n",
      " - 0s - loss: 41.6823 - val_loss: 30.7701\n",
      "Epoch 35/1000\n",
      " - 0s - loss: 39.2548 - val_loss: 23.5622\n",
      "Epoch 36/1000\n",
      " - 0s - loss: 37.5664 - val_loss: 23.3871\n",
      "Epoch 37/1000\n",
      " - 0s - loss: 36.6724 - val_loss: 19.7719\n",
      "Epoch 38/1000\n",
      " - 0s - loss: 35.4391 - val_loss: 18.6676\n",
      "Epoch 39/1000\n",
      " - 0s - loss: 33.2550 - val_loss: 18.8671\n",
      "Epoch 40/1000\n",
      " - 0s - loss: 32.9626 - val_loss: 16.1151\n",
      "Epoch 41/1000\n",
      " - 0s - loss: 29.9777 - val_loss: 15.1884\n",
      "Epoch 42/1000\n",
      " - 0s - loss: 29.6576 - val_loss: 12.4193\n",
      "Epoch 43/1000\n",
      " - 0s - loss: 27.8048 - val_loss: 11.8267\n",
      "Epoch 44/1000\n",
      " - 0s - loss: 27.6428 - val_loss: 11.2782\n",
      "Epoch 45/1000\n",
      " - 0s - loss: 27.2013 - val_loss: 10.4592\n",
      "Epoch 46/1000\n",
      " - 0s - loss: 26.2712 - val_loss: 9.3550\n",
      "Epoch 47/1000\n",
      " - 0s - loss: 24.1806 - val_loss: 11.8150\n",
      "Epoch 48/1000\n",
      " - 0s - loss: 24.5593 - val_loss: 8.3339\n",
      "Epoch 49/1000\n",
      " - 0s - loss: 24.6569 - val_loss: 7.5448\n",
      "Epoch 50/1000\n",
      " - 1s - loss: 23.8481 - val_loss: 7.3291\n",
      "Epoch 51/1000\n",
      " - 1s - loss: 22.8302 - val_loss: 6.6010\n",
      "Epoch 52/1000\n",
      " - 1s - loss: 22.9754 - val_loss: 7.0250\n",
      "Epoch 53/1000\n",
      " - 0s - loss: 22.4862 - val_loss: 5.6849\n",
      "Epoch 54/1000\n",
      " - 0s - loss: 21.0962 - val_loss: 6.5027\n",
      "Epoch 55/1000\n",
      " - 1s - loss: 21.2152 - val_loss: 8.1144\n",
      "Epoch 56/1000\n",
      " - 1s - loss: 21.4135 - val_loss: 4.4759\n",
      "Epoch 57/1000\n",
      " - 0s - loss: 19.8906 - val_loss: 5.0177\n",
      "Epoch 58/1000\n",
      " - 1s - loss: 20.0866 - val_loss: 4.4850\n",
      "Epoch 59/1000\n",
      " - 0s - loss: 21.1959 - val_loss: 4.9218\n",
      "Epoch 60/1000\n",
      " - 0s - loss: 21.6692 - val_loss: 3.4424\n",
      "Epoch 61/1000\n",
      " - 0s - loss: 19.1048 - val_loss: 9.4691\n",
      "Epoch 62/1000\n",
      " - 0s - loss: 20.3817 - val_loss: 4.1910\n",
      "Epoch 63/1000\n",
      " - 0s - loss: 18.9774 - val_loss: 2.7503\n",
      "Epoch 64/1000\n",
      " - 0s - loss: 18.8694 - val_loss: 5.8852\n",
      "Epoch 65/1000\n",
      " - 1s - loss: 18.3700 - val_loss: 2.9118\n",
      "Epoch 66/1000\n",
      " - 0s - loss: 17.5695 - val_loss: 6.4109\n",
      "Epoch 67/1000\n",
      " - 0s - loss: 19.0228 - val_loss: 4.9201\n",
      "Epoch 68/1000\n",
      " - 0s - loss: 17.9787 - val_loss: 8.9231\n",
      "Epoch 00068: early stopping\n",
      "4\n",
      "Train on 3074 samples, validate on 1318 samples\n",
      "Epoch 1/1000\n",
      " - 3s - loss: 1342.3482 - val_loss: 1108.8610\n",
      "Epoch 2/1000\n",
      " - 0s - loss: 998.2832 - val_loss: 940.5405\n",
      "Epoch 3/1000\n",
      " - 0s - loss: 851.8965 - val_loss: 807.6552\n",
      "Epoch 4/1000\n",
      " - 0s - loss: 731.9364 - val_loss: 698.5760\n",
      "Epoch 5/1000\n",
      " - 0s - loss: 634.7386 - val_loss: 610.2769\n",
      "Epoch 6/1000\n",
      " - 0s - loss: 553.8310 - val_loss: 536.7811\n",
      "Epoch 7/1000\n",
      " - 0s - loss: 488.5768 - val_loss: 476.3794\n",
      "Epoch 8/1000\n",
      " - 0s - loss: 438.4941 - val_loss: 425.3974\n",
      "Epoch 9/1000\n",
      " - 0s - loss: 393.8114 - val_loss: 381.1364\n",
      "Epoch 10/1000\n",
      " - 0s - loss: 347.8662 - val_loss: 341.4628\n",
      "Epoch 11/1000\n",
      " - 0s - loss: 315.0247 - val_loss: 304.7233\n",
      "Epoch 12/1000\n",
      " - 0s - loss: 282.0867 - val_loss: 272.4512\n",
      "Epoch 13/1000\n",
      " - 0s - loss: 251.4235 - val_loss: 242.3319\n",
      "Epoch 14/1000\n",
      " - 0s - loss: 222.4077 - val_loss: 216.3644\n",
      "Epoch 15/1000\n",
      " - 0s - loss: 202.7613 - val_loss: 192.9245\n",
      "Epoch 16/1000\n",
      " - 0s - loss: 180.9331 - val_loss: 172.6331\n",
      "Epoch 17/1000\n",
      " - 0s - loss: 164.7125 - val_loss: 154.8461\n",
      "Epoch 18/1000\n",
      " - 0s - loss: 147.1286 - val_loss: 140.4567\n",
      "Epoch 19/1000\n",
      " - 0s - loss: 135.0676 - val_loss: 124.5565\n",
      "Epoch 20/1000\n",
      " - 0s - loss: 122.8786 - val_loss: 111.9273\n",
      "Epoch 21/1000\n",
      " - 0s - loss: 112.0235 - val_loss: 101.3525\n",
      "Epoch 22/1000\n",
      " - 1s - loss: 101.6025 - val_loss: 89.9874\n",
      "Epoch 23/1000\n",
      " - 0s - loss: 93.6274 - val_loss: 82.7380\n",
      "Epoch 24/1000\n",
      " - 0s - loss: 88.5543 - val_loss: 72.6791\n",
      "Epoch 25/1000\n",
      " - 0s - loss: 79.3192 - val_loss: 67.7234\n",
      "Epoch 26/1000\n",
      " - 0s - loss: 73.3967 - val_loss: 58.7355\n",
      "Epoch 27/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 68.6296 - val_loss: 52.1934\n",
      "Epoch 28/1000\n",
      " - 0s - loss: 63.3502 - val_loss: 47.5484\n",
      "Epoch 29/1000\n",
      " - 0s - loss: 57.3420 - val_loss: 43.8926\n",
      "Epoch 30/1000\n",
      " - 0s - loss: 54.3913 - val_loss: 42.0113\n",
      "Epoch 31/1000\n",
      " - 0s - loss: 52.5040 - val_loss: 34.5382\n",
      "Epoch 32/1000\n",
      " - 0s - loss: 45.5177 - val_loss: 31.8469\n",
      "Epoch 33/1000\n",
      " - 0s - loss: 46.4566 - val_loss: 30.7856\n",
      "Epoch 34/1000\n",
      " - 0s - loss: 39.9223 - val_loss: 25.6103\n",
      "Epoch 35/1000\n",
      " - 0s - loss: 39.8273 - val_loss: 24.9585\n",
      "Epoch 36/1000\n",
      " - 0s - loss: 35.9623 - val_loss: 21.0534\n",
      "Epoch 37/1000\n",
      " - 0s - loss: 34.7538 - val_loss: 28.1779\n",
      "Epoch 38/1000\n",
      " - 0s - loss: 35.1139 - val_loss: 19.9536\n",
      "Epoch 39/1000\n",
      " - 0s - loss: 31.8268 - val_loss: 18.0889\n",
      "Epoch 40/1000\n",
      " - 0s - loss: 30.6327 - val_loss: 14.9775\n",
      "Epoch 41/1000\n",
      " - 0s - loss: 30.1213 - val_loss: 15.1056\n",
      "Epoch 42/1000\n",
      " - 0s - loss: 29.8669 - val_loss: 12.1324\n",
      "Epoch 43/1000\n",
      " - 0s - loss: 26.9130 - val_loss: 10.3893\n",
      "Epoch 44/1000\n",
      " - 0s - loss: 29.0374 - val_loss: 9.9787\n",
      "Epoch 45/1000\n",
      " - 0s - loss: 27.4466 - val_loss: 10.5870\n",
      "Epoch 46/1000\n",
      " - 0s - loss: 26.6208 - val_loss: 8.6635\n",
      "Epoch 47/1000\n",
      " - 0s - loss: 25.4161 - val_loss: 9.2450\n",
      "Epoch 48/1000\n",
      " - 0s - loss: 25.0595 - val_loss: 9.4219\n",
      "Epoch 49/1000\n",
      " - 0s - loss: 24.8267 - val_loss: 10.4911\n",
      "Epoch 50/1000\n",
      " - 0s - loss: 22.7975 - val_loss: 6.8642\n",
      "Epoch 51/1000\n",
      " - 0s - loss: 23.3605 - val_loss: 6.5588\n",
      "Epoch 52/1000\n",
      " - 0s - loss: 21.4604 - val_loss: 6.1717\n",
      "Epoch 53/1000\n",
      " - 0s - loss: 22.6848 - val_loss: 5.3339\n",
      "Epoch 54/1000\n",
      " - 0s - loss: 21.5925 - val_loss: 4.8657\n",
      "Epoch 55/1000\n",
      " - 0s - loss: 21.6903 - val_loss: 10.8345\n",
      "Epoch 56/1000\n",
      " - 0s - loss: 22.7977 - val_loss: 5.9464\n",
      "Epoch 57/1000\n",
      " - 0s - loss: 20.7105 - val_loss: 8.2485\n",
      "Epoch 58/1000\n",
      " - 0s - loss: 21.0167 - val_loss: 4.4446\n",
      "Epoch 59/1000\n",
      " - 0s - loss: 21.1226 - val_loss: 3.5781\n",
      "Epoch 60/1000\n",
      " - 0s - loss: 19.2054 - val_loss: 4.1002\n",
      "Epoch 61/1000\n",
      " - 0s - loss: 19.4318 - val_loss: 4.4881\n",
      "Epoch 62/1000\n",
      " - 0s - loss: 19.6213 - val_loss: 3.0090\n",
      "Epoch 63/1000\n",
      " - 0s - loss: 18.5211 - val_loss: 4.3268\n",
      "Epoch 64/1000\n",
      " - 0s - loss: 18.7561 - val_loss: 8.4379\n",
      "Epoch 65/1000\n",
      " - 0s - loss: 19.3859 - val_loss: 4.2552\n",
      "Epoch 66/1000\n",
      " - 0s - loss: 18.8568 - val_loss: 4.2695\n",
      "Epoch 67/1000\n",
      " - 0s - loss: 17.7406 - val_loss: 6.4236\n",
      "Epoch 00067: early stopping\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath=r\"G:\\215\\network_best2.hdf5\", verbose=0, save_best_only=True) # save best model\n",
    "\n",
    "for i in range(5):\n",
    "    print(i)\n",
    "    model_regression= Sequential()\n",
    "    model_regression.add(Dense(150,input_dim=X_train.shape[1], activation='tanh')) # Hidden 1     #  why input_dim=x.shape[1]?  \n",
    "    model_regression.add(Dropout(0.10))\n",
    "    model_regression.add(Dense(100,activation='tanh')) # Hidden 2\n",
    "    model_regression.add(Dropout(0.10))\n",
    "    model_regression.add(Dense(50,activation='tanh'))\n",
    "    model_regression.add(Dropout(0.10))\n",
    "    model_regression.add(Dense(1))\n",
    "    \n",
    "    #model_regression.add(Dense(y_train.shape[2],activation='softmax')) # Output\n",
    "    model_regression.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=5, verbose=1, mode='auto')\n",
    "    \n",
    "    model_regression.fit(X_train, y_train,validation_data=(X_test,y_test),callbacks=[monitor,checkpointer],verbose=2,epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (MSE): 2.5936110924904785\n",
      "Final score (RMSE): 1.6104692150086193\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "model_regression.load_weights(r\"G:\\215\\network_best2.hdf5\")\n",
    "\n",
    "pred = model_regression.predict(X_test)\n",
    "\n",
    "score = metrics.mean_squared_error(pred,y_test)\n",
    "print(\"Final score (MSE): {}\".format(score))\n",
    "\n",
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "print(\"Final score (RMSE): {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Train on 3074 samples, validate on 1318 samples\n",
      "Epoch 1/1000\n",
      " - 2s - loss: 1434.5256 - val_loss: 1207.7169\n",
      "Epoch 2/1000\n",
      " - 0s - loss: 1084.0845 - val_loss: 1017.6890\n",
      "Epoch 3/1000\n",
      " - 0s - loss: 923.5782 - val_loss: 875.4117\n",
      "Epoch 4/1000\n",
      " - 0s - loss: 793.2146 - val_loss: 756.6898\n",
      "Epoch 5/1000\n",
      " - 0s - loss: 688.6029 - val_loss: 660.2468\n",
      "Epoch 6/1000\n",
      " - 0s - loss: 599.5834 - val_loss: 580.9188\n",
      "Epoch 7/1000\n",
      " - 0s - loss: 531.8334 - val_loss: 514.9895\n",
      "Epoch 8/1000\n",
      " - 0s - loss: 472.0007 - val_loss: 458.8725\n",
      "Epoch 9/1000\n",
      " - 0s - loss: 421.5019 - val_loss: 409.3436\n",
      "Epoch 10/1000\n",
      " - 0s - loss: 375.4133 - val_loss: 364.9216\n",
      "Epoch 11/1000\n",
      " - 0s - loss: 336.3247 - val_loss: 327.8376\n",
      "Epoch 12/1000\n",
      " - 0s - loss: 301.0956 - val_loss: 293.4767\n",
      "Epoch 13/1000\n",
      " - 0s - loss: 271.9975 - val_loss: 262.8171\n",
      "Epoch 14/1000\n",
      " - 0s - loss: 245.1025 - val_loss: 233.7812\n",
      "Epoch 15/1000\n",
      " - 0s - loss: 219.7122 - val_loss: 209.3192\n",
      "Epoch 16/1000\n",
      " - 0s - loss: 197.3641 - val_loss: 186.7977\n",
      "Epoch 17/1000\n",
      " - 0s - loss: 181.2708 - val_loss: 167.7189\n",
      "Epoch 18/1000\n",
      " - 0s - loss: 163.5504 - val_loss: 150.6197\n",
      "Epoch 19/1000\n",
      " - 0s - loss: 145.0134 - val_loss: 134.8978\n",
      "Epoch 20/1000\n",
      " - 0s - loss: 132.3274 - val_loss: 121.7676\n",
      "Epoch 21/1000\n",
      " - 0s - loss: 120.6915 - val_loss: 109.5577\n",
      "Epoch 22/1000\n",
      " - 0s - loss: 108.7672 - val_loss: 97.6376\n",
      "Epoch 23/1000\n",
      " - 0s - loss: 99.4652 - val_loss: 87.8621\n",
      "Epoch 24/1000\n",
      " - 0s - loss: 92.6996 - val_loss: 82.0349\n",
      "Epoch 25/1000\n",
      " - 0s - loss: 85.3033 - val_loss: 72.1344\n",
      "Epoch 26/1000\n",
      " - 0s - loss: 77.4220 - val_loss: 64.0524\n",
      "Epoch 27/1000\n",
      " - 0s - loss: 70.8916 - val_loss: 57.6567\n",
      "Epoch 28/1000\n",
      " - 0s - loss: 66.3236 - val_loss: 52.0208\n",
      "Epoch 29/1000\n",
      " - 0s - loss: 60.6519 - val_loss: 46.9923\n",
      "Epoch 30/1000\n",
      " - 0s - loss: 57.4858 - val_loss: 42.2654\n",
      "Epoch 31/1000\n",
      " - 0s - loss: 55.0474 - val_loss: 41.2054\n",
      "Epoch 32/1000\n",
      " - 0s - loss: 51.3677 - val_loss: 34.5364\n",
      "Epoch 33/1000\n",
      " - 0s - loss: 46.3222 - val_loss: 29.7581\n",
      "Epoch 34/1000\n",
      " - 0s - loss: 43.1420 - val_loss: 27.0606\n",
      "Epoch 35/1000\n",
      " - 0s - loss: 40.0588 - val_loss: 26.0495\n",
      "Epoch 36/1000\n",
      " - 0s - loss: 40.3704 - val_loss: 22.3761\n",
      "Epoch 37/1000\n",
      " - 0s - loss: 38.2297 - val_loss: 19.8360\n",
      "Epoch 38/1000\n",
      " - 0s - loss: 35.2614 - val_loss: 19.0850\n",
      "Epoch 39/1000\n",
      " - 0s - loss: 35.7123 - val_loss: 17.6869\n",
      "Epoch 40/1000\n",
      " - 0s - loss: 33.0621 - val_loss: 17.6974\n",
      "Epoch 41/1000\n",
      " - 0s - loss: 31.6615 - val_loss: 14.0486\n",
      "Epoch 42/1000\n",
      " - 0s - loss: 30.8737 - val_loss: 14.0876\n",
      "Epoch 43/1000\n",
      " - 0s - loss: 29.2128 - val_loss: 12.8513\n",
      "Epoch 44/1000\n",
      " - 0s - loss: 27.3028 - val_loss: 11.6810\n",
      "Epoch 45/1000\n",
      " - 0s - loss: 27.8075 - val_loss: 10.1572\n",
      "Epoch 46/1000\n",
      " - 0s - loss: 27.3188 - val_loss: 8.6849\n",
      "Epoch 47/1000\n",
      " - 0s - loss: 25.1072 - val_loss: 14.0060\n",
      "Epoch 48/1000\n",
      " - 0s - loss: 26.6648 - val_loss: 11.2985\n",
      "Epoch 49/1000\n",
      " - 0s - loss: 24.8423 - val_loss: 9.5261\n",
      "Epoch 50/1000\n",
      " - 0s - loss: 24.9587 - val_loss: 7.0048\n",
      "Epoch 51/1000\n",
      " - 0s - loss: 23.9650 - val_loss: 5.9013\n",
      "Epoch 52/1000\n",
      " - 0s - loss: 23.6682 - val_loss: 8.7247\n",
      "Epoch 53/1000\n",
      " - 0s - loss: 25.9350 - val_loss: 7.2720\n",
      "Epoch 54/1000\n",
      " - 0s - loss: 23.4725 - val_loss: 6.3547\n",
      "Epoch 55/1000\n",
      " - 0s - loss: 22.9751 - val_loss: 4.7333\n",
      "Epoch 56/1000\n",
      " - 0s - loss: 21.8371 - val_loss: 10.5461\n",
      "Epoch 57/1000\n",
      " - 0s - loss: 22.7462 - val_loss: 3.6934\n",
      "Epoch 58/1000\n",
      " - 0s - loss: 21.4814 - val_loss: 4.3003\n",
      "Epoch 59/1000\n",
      " - 0s - loss: 19.8155 - val_loss: 6.9968\n",
      "Epoch 60/1000\n",
      " - 0s - loss: 20.1150 - val_loss: 7.5237\n",
      "Epoch 61/1000\n",
      " - 0s - loss: 20.6162 - val_loss: 2.8979\n",
      "Epoch 62/1000\n",
      " - 0s - loss: 20.0745 - val_loss: 3.3164\n",
      "Epoch 63/1000\n",
      " - 0s - loss: 20.4858 - val_loss: 3.8405\n",
      "Epoch 64/1000\n",
      " - 0s - loss: 20.9375 - val_loss: 3.2001\n",
      "Epoch 65/1000\n",
      " - 0s - loss: 19.5401 - val_loss: 3.0430\n",
      "Epoch 66/1000\n",
      " - 0s - loss: 20.3953 - val_loss: 3.8264\n",
      "Epoch 00066: early stopping\n",
      "1\n",
      "Train on 3074 samples, validate on 1318 samples\n",
      "Epoch 1/1000\n",
      " - 2s - loss: 1444.7982 - val_loss: 1218.8826\n",
      "Epoch 2/1000\n",
      " - 0s - loss: 1095.0167 - val_loss: 1028.4186\n",
      "Epoch 3/1000\n",
      " - 0s - loss: 935.1883 - val_loss: 886.7375\n",
      "Epoch 4/1000\n",
      " - 0s - loss: 807.7136 - val_loss: 769.7615\n",
      "Epoch 5/1000\n",
      " - 0s - loss: 700.6209 - val_loss: 670.0099\n",
      "Epoch 6/1000\n",
      " - 0s - loss: 608.2582 - val_loss: 588.9063\n",
      "Epoch 7/1000\n",
      " - 0s - loss: 535.3608 - val_loss: 520.4931\n",
      "Epoch 8/1000\n",
      " - 0s - loss: 474.6005 - val_loss: 462.0717\n",
      "Epoch 9/1000\n",
      " - 0s - loss: 422.4970 - val_loss: 411.8809\n",
      "Epoch 10/1000\n",
      " - 0s - loss: 378.6303 - val_loss: 369.8566\n",
      "Epoch 11/1000\n",
      " - 0s - loss: 336.4153 - val_loss: 329.9367\n",
      "Epoch 12/1000\n",
      " - 0s - loss: 305.0222 - val_loss: 295.7923\n",
      "Epoch 13/1000\n",
      " - 0s - loss: 271.4421 - val_loss: 266.4986\n",
      "Epoch 14/1000\n",
      " - 0s - loss: 245.3503 - val_loss: 236.3349\n",
      "Epoch 15/1000\n",
      " - 0s - loss: 221.1060 - val_loss: 211.5997\n",
      "Epoch 16/1000\n",
      " - 0s - loss: 199.0710 - val_loss: 190.2015\n",
      "Epoch 17/1000\n",
      " - 0s - loss: 182.6018 - val_loss: 169.3046\n",
      "Epoch 18/1000\n",
      " - 0s - loss: 161.9340 - val_loss: 152.7991\n",
      "Epoch 19/1000\n",
      " - 0s - loss: 145.5537 - val_loss: 136.6744\n",
      "Epoch 20/1000\n",
      " - 0s - loss: 131.5436 - val_loss: 124.4261\n",
      "Epoch 21/1000\n",
      " - 0s - loss: 122.8686 - val_loss: 111.3008\n",
      "Epoch 22/1000\n",
      " - 0s - loss: 110.7384 - val_loss: 101.2420\n",
      "Epoch 23/1000\n",
      " - 0s - loss: 102.7630 - val_loss: 89.2214\n",
      "Epoch 24/1000\n",
      " - 0s - loss: 93.8062 - val_loss: 81.7423\n",
      "Epoch 25/1000\n",
      " - 0s - loss: 82.8905 - val_loss: 73.0150\n",
      "Epoch 26/1000\n",
      " - 0s - loss: 80.1403 - val_loss: 66.5265\n",
      "Epoch 27/1000\n",
      " - 0s - loss: 74.6462 - val_loss: 59.6299\n",
      "Epoch 28/1000\n",
      " - 0s - loss: 67.4351 - val_loss: 53.5428\n",
      "Epoch 29/1000\n",
      " - 0s - loss: 63.5285 - val_loss: 51.8450\n",
      "Epoch 30/1000\n",
      " - 0s - loss: 55.8448 - val_loss: 42.4752\n",
      "Epoch 31/1000\n",
      " - 0s - loss: 55.4212 - val_loss: 41.1785\n",
      "Epoch 32/1000\n",
      " - 0s - loss: 49.5688 - val_loss: 34.2881\n",
      "Epoch 33/1000\n",
      " - 0s - loss: 46.3396 - val_loss: 32.1856\n",
      "Epoch 34/1000\n",
      " - 0s - loss: 42.8135 - val_loss: 29.1365\n",
      "Epoch 35/1000\n",
      " - 0s - loss: 42.1173 - val_loss: 26.9855\n",
      "Epoch 36/1000\n",
      " - 0s - loss: 38.7818 - val_loss: 22.5002\n",
      "Epoch 37/1000\n",
      " - 0s - loss: 37.4058 - val_loss: 20.8958\n",
      "Epoch 38/1000\n",
      " - 0s - loss: 36.1864 - val_loss: 18.5022\n",
      "Epoch 39/1000\n",
      " - 0s - loss: 32.9064 - val_loss: 16.8503\n",
      "Epoch 40/1000\n",
      " - 0s - loss: 32.2001 - val_loss: 16.8929\n",
      "Epoch 41/1000\n",
      " - 0s - loss: 32.9467 - val_loss: 13.9034\n",
      "Epoch 42/1000\n",
      " - 0s - loss: 29.3736 - val_loss: 18.4724\n",
      "Epoch 43/1000\n",
      " - 0s - loss: 30.4342 - val_loss: 16.1930\n",
      "Epoch 44/1000\n",
      " - 0s - loss: 29.0918 - val_loss: 12.0168\n",
      "Epoch 45/1000\n",
      " - 0s - loss: 26.3752 - val_loss: 12.1650\n",
      "Epoch 46/1000\n",
      " - 0s - loss: 26.8206 - val_loss: 9.6435\n",
      "Epoch 47/1000\n",
      " - 0s - loss: 25.6790 - val_loss: 10.1073\n",
      "Epoch 48/1000\n",
      " - 0s - loss: 25.3696 - val_loss: 9.6927\n",
      "Epoch 49/1000\n",
      " - 0s - loss: 24.7924 - val_loss: 7.2657\n",
      "Epoch 50/1000\n",
      " - 0s - loss: 23.4689 - val_loss: 13.6900\n",
      "Epoch 51/1000\n",
      " - 0s - loss: 23.8315 - val_loss: 7.6891\n",
      "Epoch 52/1000\n",
      " - 0s - loss: 22.3620 - val_loss: 7.5606\n",
      "Epoch 53/1000\n",
      " - 0s - loss: 21.6230 - val_loss: 6.8687\n",
      "Epoch 54/1000\n",
      " - 0s - loss: 22.4960 - val_loss: 6.1472\n",
      "Epoch 55/1000\n",
      " - 0s - loss: 21.3700 - val_loss: 6.3082\n",
      "Epoch 56/1000\n",
      " - 0s - loss: 20.0062 - val_loss: 7.6201\n",
      "Epoch 57/1000\n",
      " - 0s - loss: 19.7828 - val_loss: 4.2832\n",
      "Epoch 58/1000\n",
      " - 0s - loss: 19.8972 - val_loss: 6.6040\n",
      "Epoch 59/1000\n",
      " - 0s - loss: 20.7382 - val_loss: 5.0968\n",
      "Epoch 60/1000\n",
      " - 0s - loss: 20.1046 - val_loss: 6.0241\n",
      "Epoch 61/1000\n",
      " - 0s - loss: 19.3544 - val_loss: 3.8561\n",
      "Epoch 62/1000\n",
      " - 0s - loss: 19.2151 - val_loss: 6.3634\n",
      "Epoch 63/1000\n",
      " - 0s - loss: 18.4832 - val_loss: 5.6893\n",
      "Epoch 64/1000\n",
      " - 0s - loss: 18.4595 - val_loss: 7.1338\n",
      "Epoch 65/1000\n",
      " - 0s - loss: 18.2593 - val_loss: 3.2865\n",
      "Epoch 66/1000\n",
      " - 0s - loss: 18.5957 - val_loss: 3.9526\n",
      "Epoch 67/1000\n",
      " - 0s - loss: 17.9779 - val_loss: 4.8941\n",
      "Epoch 68/1000\n",
      " - 0s - loss: 18.1158 - val_loss: 2.7046\n",
      "Epoch 69/1000\n",
      " - 0s - loss: 17.6952 - val_loss: 3.0226\n",
      "Epoch 70/1000\n",
      " - 0s - loss: 17.0802 - val_loss: 2.9027\n",
      "Epoch 71/1000\n",
      " - 0s - loss: 18.4723 - val_loss: 2.4397\n",
      "Epoch 72/1000\n",
      " - 0s - loss: 17.6146 - val_loss: 2.3573\n",
      "Epoch 73/1000\n",
      " - 0s - loss: 16.9163 - val_loss: 3.4082\n",
      "Epoch 74/1000\n",
      " - 0s - loss: 16.2566 - val_loss: 3.3617\n",
      "Epoch 75/1000\n",
      " - 0s - loss: 16.2962 - val_loss: 2.5398\n",
      "Epoch 76/1000\n",
      " - 0s - loss: 16.6216 - val_loss: 4.1239\n",
      "Epoch 77/1000\n",
      " - 0s - loss: 17.4033 - val_loss: 9.6111\n",
      "Epoch 00077: early stopping\n",
      "2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3074 samples, validate on 1318 samples\n",
      "Epoch 1/1000\n",
      " - 2s - loss: 1406.1977 - val_loss: 1173.8946\n",
      "Epoch 2/1000\n",
      " - 0s - loss: 1053.6469 - val_loss: 993.2812\n",
      "Epoch 3/1000\n",
      " - 0s - loss: 898.9799 - val_loss: 853.2612\n",
      "Epoch 4/1000\n",
      " - 0s - loss: 773.5100 - val_loss: 737.7818\n",
      "Epoch 5/1000\n",
      " - 0s - loss: 672.1815 - val_loss: 643.5362\n",
      "Epoch 6/1000\n",
      " - 0s - loss: 587.1277 - val_loss: 566.8248\n",
      "Epoch 7/1000\n",
      " - 0s - loss: 516.2942 - val_loss: 501.7348\n",
      "Epoch 8/1000\n",
      " - 0s - loss: 460.6193 - val_loss: 446.8170\n",
      "Epoch 9/1000\n",
      " - 0s - loss: 411.4632 - val_loss: 399.5390\n",
      "Epoch 10/1000\n",
      " - 0s - loss: 366.7574 - val_loss: 357.2523\n",
      "Epoch 11/1000\n",
      " - 0s - loss: 330.1837 - val_loss: 320.5156\n",
      "Epoch 12/1000\n",
      " - 0s - loss: 298.4815 - val_loss: 286.2375\n",
      "Epoch 13/1000\n",
      " - 0s - loss: 263.4612 - val_loss: 256.5369\n",
      "Epoch 14/1000\n",
      " - 0s - loss: 236.5224 - val_loss: 228.8873\n",
      "Epoch 15/1000\n",
      " - 0s - loss: 212.4301 - val_loss: 203.6194\n",
      "Epoch 16/1000\n",
      " - 0s - loss: 192.1824 - val_loss: 181.4985\n",
      "Epoch 17/1000\n",
      " - 0s - loss: 172.4484 - val_loss: 162.3686\n",
      "Epoch 18/1000\n",
      " - 0s - loss: 154.5322 - val_loss: 145.1688\n",
      "Epoch 19/1000\n",
      " - 0s - loss: 141.4794 - val_loss: 132.3236\n",
      "Epoch 20/1000\n",
      " - 0s - loss: 128.8629 - val_loss: 117.2593\n",
      "Epoch 21/1000\n",
      " - 0s - loss: 117.7627 - val_loss: 107.3628\n",
      "Epoch 22/1000\n",
      " - 0s - loss: 106.9708 - val_loss: 95.4728\n",
      "Epoch 23/1000\n",
      " - 0s - loss: 98.7297 - val_loss: 85.3984\n",
      "Epoch 24/1000\n",
      " - 0s - loss: 89.7591 - val_loss: 77.9706\n",
      "Epoch 25/1000\n",
      " - 0s - loss: 82.3088 - val_loss: 69.1575\n",
      "Epoch 26/1000\n",
      " - 0s - loss: 78.0260 - val_loss: 61.2741\n",
      "Epoch 27/1000\n",
      " - 0s - loss: 68.6363 - val_loss: 56.1118\n",
      "Epoch 28/1000\n",
      " - 0s - loss: 66.3695 - val_loss: 50.2228\n",
      "Epoch 29/1000\n",
      " - 0s - loss: 61.0383 - val_loss: 46.2743\n",
      "Epoch 30/1000\n",
      " - 0s - loss: 55.7872 - val_loss: 39.7150\n",
      "Epoch 31/1000\n",
      " - 0s - loss: 52.8482 - val_loss: 37.1136\n",
      "Epoch 32/1000\n",
      " - 0s - loss: 49.7922 - val_loss: 35.5637\n",
      "Epoch 33/1000\n",
      " - 0s - loss: 44.7425 - val_loss: 31.8400\n",
      "Epoch 34/1000\n",
      " - 0s - loss: 42.2411 - val_loss: 26.9947\n",
      "Epoch 35/1000\n",
      " - 0s - loss: 39.8965 - val_loss: 24.6187\n",
      "Epoch 36/1000\n",
      " - 0s - loss: 38.6562 - val_loss: 23.6282\n",
      "Epoch 37/1000\n",
      " - 0s - loss: 37.3232 - val_loss: 19.9753\n",
      "Epoch 38/1000\n",
      " - 0s - loss: 33.9963 - val_loss: 17.4284\n",
      "Epoch 39/1000\n",
      " - 0s - loss: 33.8277 - val_loss: 17.1454\n",
      "Epoch 40/1000\n",
      " - 0s - loss: 32.8177 - val_loss: 17.4907\n",
      "Epoch 41/1000\n",
      " - 0s - loss: 29.4043 - val_loss: 14.9049\n",
      "Epoch 42/1000\n",
      " - 0s - loss: 30.0235 - val_loss: 12.5253\n",
      "Epoch 43/1000\n",
      " - 0s - loss: 29.3758 - val_loss: 12.0608\n",
      "Epoch 44/1000\n",
      " - 0s - loss: 26.8203 - val_loss: 10.5943\n",
      "Epoch 45/1000\n",
      " - 0s - loss: 27.0523 - val_loss: 10.1229\n",
      "Epoch 46/1000\n",
      " - 0s - loss: 27.3713 - val_loss: 10.1644\n",
      "Epoch 47/1000\n",
      " - 0s - loss: 25.4009 - val_loss: 7.6679\n",
      "Epoch 48/1000\n",
      " - 0s - loss: 24.9263 - val_loss: 9.3727\n",
      "Epoch 49/1000\n",
      " - 0s - loss: 24.3604 - val_loss: 8.3371\n",
      "Epoch 50/1000\n",
      " - 0s - loss: 24.3332 - val_loss: 9.9256\n",
      "Epoch 51/1000\n",
      " - 0s - loss: 24.5513 - val_loss: 6.8118\n",
      "Epoch 52/1000\n",
      " - 0s - loss: 23.0094 - val_loss: 11.0122\n",
      "Epoch 53/1000\n",
      " - 0s - loss: 22.5371 - val_loss: 6.5234\n",
      "Epoch 54/1000\n",
      " - 0s - loss: 23.7668 - val_loss: 6.7089\n",
      "Epoch 55/1000\n",
      " - 0s - loss: 22.4094 - val_loss: 6.8345\n",
      "Epoch 56/1000\n",
      " - 0s - loss: 21.7206 - val_loss: 4.7696\n",
      "Epoch 57/1000\n",
      " - 0s - loss: 22.8784 - val_loss: 4.6591\n",
      "Epoch 58/1000\n",
      " - 0s - loss: 19.8043 - val_loss: 3.9876\n",
      "Epoch 59/1000\n",
      " - 0s - loss: 21.0784 - val_loss: 9.5942\n",
      "Epoch 60/1000\n",
      " - 0s - loss: 21.6822 - val_loss: 5.2066\n",
      "Epoch 61/1000\n",
      " - 0s - loss: 21.6824 - val_loss: 3.9853\n",
      "Epoch 62/1000\n",
      " - 0s - loss: 20.0100 - val_loss: 3.4439\n",
      "Epoch 63/1000\n",
      " - 0s - loss: 19.8721 - val_loss: 2.6218\n",
      "Epoch 64/1000\n",
      " - 0s - loss: 20.6115 - val_loss: 3.6189\n",
      "Epoch 65/1000\n",
      " - 0s - loss: 18.4792 - val_loss: 5.0194\n",
      "Epoch 66/1000\n",
      " - 0s - loss: 18.1856 - val_loss: 3.3929\n",
      "Epoch 67/1000\n",
      " - 0s - loss: 18.4300 - val_loss: 3.9499\n",
      "Epoch 68/1000\n",
      " - 0s - loss: 18.7830 - val_loss: 8.3373\n",
      "Epoch 00068: early stopping\n",
      "3\n",
      "Train on 3074 samples, validate on 1318 samples\n",
      "Epoch 1/1000\n",
      " - 2s - loss: 1426.8552 - val_loss: 1191.6892\n",
      "Epoch 2/1000\n",
      " - 0s - loss: 1067.4009 - val_loss: 1003.3375\n",
      "Epoch 3/1000\n",
      " - 0s - loss: 909.6600 - val_loss: 864.4014\n",
      "Epoch 4/1000\n",
      " - 0s - loss: 784.1924 - val_loss: 750.0859\n",
      "Epoch 5/1000\n",
      " - 0s - loss: 682.9782 - val_loss: 654.9410\n",
      "Epoch 6/1000\n",
      " - 0s - loss: 596.2053 - val_loss: 575.0338\n",
      "Epoch 7/1000\n",
      " - 0s - loss: 528.6678 - val_loss: 511.3880\n",
      "Epoch 8/1000\n",
      " - 0s - loss: 466.3147 - val_loss: 455.4650\n",
      "Epoch 9/1000\n",
      " - 0s - loss: 421.1276 - val_loss: 407.5835\n",
      "Epoch 10/1000\n",
      " - 0s - loss: 373.3592 - val_loss: 365.2890\n",
      "Epoch 11/1000\n",
      " - 0s - loss: 336.3061 - val_loss: 328.3694\n",
      "Epoch 12/1000\n",
      " - 0s - loss: 302.5880 - val_loss: 293.8138\n",
      "Epoch 13/1000\n",
      " - 0s - loss: 272.9334 - val_loss: 263.2825\n",
      "Epoch 14/1000\n",
      " - 0s - loss: 246.1610 - val_loss: 234.7523\n",
      "Epoch 15/1000\n",
      " - 0s - loss: 218.1281 - val_loss: 209.0225\n",
      "Epoch 16/1000\n",
      " - 0s - loss: 199.7951 - val_loss: 186.6209\n",
      "Epoch 17/1000\n",
      " - 0s - loss: 177.7326 - val_loss: 167.2376\n",
      "Epoch 18/1000\n",
      " - 0s - loss: 157.5272 - val_loss: 149.3788\n",
      "Epoch 19/1000\n",
      " - 0s - loss: 145.0822 - val_loss: 135.6843\n",
      "Epoch 20/1000\n",
      " - 0s - loss: 132.7776 - val_loss: 121.0191\n",
      "Epoch 21/1000\n",
      " - 0s - loss: 119.0145 - val_loss: 109.6011\n",
      "Epoch 22/1000\n",
      " - 0s - loss: 110.1863 - val_loss: 98.0636\n",
      "Epoch 23/1000\n",
      " - 0s - loss: 99.5981 - val_loss: 88.7307\n",
      "Epoch 24/1000\n",
      " - 0s - loss: 91.8550 - val_loss: 79.1448\n",
      "Epoch 25/1000\n",
      " - 0s - loss: 87.2508 - val_loss: 71.1944\n",
      "Epoch 26/1000\n",
      " - 0s - loss: 74.5672 - val_loss: 65.1769\n",
      "Epoch 27/1000\n",
      " - 0s - loss: 71.0709 - val_loss: 57.3933\n",
      "Epoch 28/1000\n",
      " - 0s - loss: 65.8711 - val_loss: 51.3081\n",
      "Epoch 29/1000\n",
      " - 0s - loss: 62.3481 - val_loss: 48.0799\n",
      "Epoch 30/1000\n",
      " - 0s - loss: 56.7486 - val_loss: 42.6259\n",
      "Epoch 31/1000\n",
      " - 0s - loss: 52.7605 - val_loss: 39.2757\n",
      "Epoch 32/1000\n",
      " - 0s - loss: 49.4754 - val_loss: 36.4140\n",
      "Epoch 33/1000\n",
      " - 0s - loss: 46.9677 - val_loss: 30.3515\n",
      "Epoch 34/1000\n",
      " - 0s - loss: 42.8341 - val_loss: 29.7906\n",
      "Epoch 35/1000\n",
      " - 0s - loss: 40.1926 - val_loss: 27.6470\n",
      "Epoch 36/1000\n",
      " - 0s - loss: 37.8182 - val_loss: 22.7099\n",
      "Epoch 37/1000\n",
      " - 0s - loss: 37.9394 - val_loss: 22.8054\n",
      "Epoch 38/1000\n",
      " - 0s - loss: 33.4327 - val_loss: 25.8569\n",
      "Epoch 39/1000\n",
      " - 0s - loss: 34.2438 - val_loss: 19.9213\n",
      "Epoch 40/1000\n",
      " - 0s - loss: 33.3082 - val_loss: 15.6806\n",
      "Epoch 41/1000\n",
      " - 0s - loss: 30.9934 - val_loss: 14.2191\n",
      "Epoch 42/1000\n",
      " - 0s - loss: 33.1653 - val_loss: 14.7176\n",
      "Epoch 43/1000\n",
      " - 0s - loss: 30.7167 - val_loss: 12.6202\n",
      "Epoch 44/1000\n",
      " - 0s - loss: 28.2209 - val_loss: 15.1634\n",
      "Epoch 45/1000\n",
      " - 0s - loss: 28.1106 - val_loss: 10.8873\n",
      "Epoch 46/1000\n",
      " - 0s - loss: 28.2740 - val_loss: 10.2387\n",
      "Epoch 47/1000\n",
      " - 0s - loss: 25.3363 - val_loss: 9.3108\n",
      "Epoch 48/1000\n",
      " - 0s - loss: 24.6008 - val_loss: 20.9133\n",
      "Epoch 49/1000\n",
      " - 0s - loss: 24.9549 - val_loss: 12.0229\n",
      "Epoch 50/1000\n",
      " - 0s - loss: 23.4889 - val_loss: 10.0000\n",
      "Epoch 51/1000\n",
      " - 0s - loss: 24.1650 - val_loss: 6.6539\n",
      "Epoch 52/1000\n",
      " - 0s - loss: 22.9353 - val_loss: 9.4854\n",
      "Epoch 53/1000\n",
      " - 0s - loss: 24.0616 - val_loss: 6.9838\n",
      "Epoch 54/1000\n",
      " - 0s - loss: 22.9917 - val_loss: 8.0037\n",
      "Epoch 55/1000\n",
      " - 0s - loss: 21.3550 - val_loss: 5.0987\n",
      "Epoch 56/1000\n",
      " - 0s - loss: 20.1299 - val_loss: 5.2121\n",
      "Epoch 57/1000\n",
      " - 0s - loss: 21.7809 - val_loss: 5.9417\n",
      "Epoch 58/1000\n",
      " - 0s - loss: 20.8761 - val_loss: 4.7131\n",
      "Epoch 59/1000\n",
      " - 0s - loss: 19.7818 - val_loss: 6.5295\n",
      "Epoch 60/1000\n",
      " - 0s - loss: 21.2982 - val_loss: 4.6095\n",
      "Epoch 61/1000\n",
      " - 0s - loss: 21.0390 - val_loss: 8.4385\n",
      "Epoch 62/1000\n",
      " - 0s - loss: 20.1375 - val_loss: 4.1179\n",
      "Epoch 63/1000\n",
      " - 0s - loss: 19.9716 - val_loss: 4.9322\n",
      "Epoch 64/1000\n",
      " - 0s - loss: 20.1458 - val_loss: 5.4740\n",
      "Epoch 65/1000\n",
      " - 0s - loss: 19.3928 - val_loss: 2.9731\n",
      "Epoch 66/1000\n",
      " - 0s - loss: 17.9659 - val_loss: 6.3740\n",
      "Epoch 67/1000\n",
      " - 0s - loss: 19.3288 - val_loss: 2.4873\n",
      "Epoch 68/1000\n",
      " - 0s - loss: 16.5715 - val_loss: 2.2274\n",
      "Epoch 69/1000\n",
      " - 0s - loss: 18.7959 - val_loss: 3.4686\n",
      "Epoch 70/1000\n",
      " - 0s - loss: 17.9574 - val_loss: 3.1439\n",
      "Epoch 71/1000\n",
      " - 0s - loss: 17.6869 - val_loss: 2.6635\n",
      "Epoch 72/1000\n",
      " - 0s - loss: 17.6242 - val_loss: 5.9588\n",
      "Epoch 73/1000\n",
      " - 0s - loss: 17.7830 - val_loss: 2.9024\n",
      "Epoch 00073: early stopping\n",
      "4\n",
      "Train on 3074 samples, validate on 1318 samples\n",
      "Epoch 1/1000\n",
      " - 3s - loss: 1422.2429 - val_loss: 1184.6973\n",
      "Epoch 2/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 1063.5202 - val_loss: 998.0587\n",
      "Epoch 3/1000\n",
      " - 0s - loss: 904.1239 - val_loss: 857.7635\n",
      "Epoch 4/1000\n",
      " - 0s - loss: 778.5660 - val_loss: 742.1250\n",
      "Epoch 5/1000\n",
      " - 0s - loss: 675.9237 - val_loss: 646.9269\n",
      "Epoch 6/1000\n",
      " - 0s - loss: 590.4197 - val_loss: 570.0799\n",
      "Epoch 7/1000\n",
      " - 0s - loss: 519.9579 - val_loss: 507.0754\n",
      "Epoch 8/1000\n",
      " - 0s - loss: 467.5423 - val_loss: 452.4831\n",
      "Epoch 9/1000\n",
      " - 0s - loss: 416.1043 - val_loss: 406.1570\n",
      "Epoch 10/1000\n",
      " - 0s - loss: 372.3728 - val_loss: 363.7360\n",
      "Epoch 11/1000\n",
      " - 0s - loss: 336.8432 - val_loss: 325.6795\n",
      "Epoch 12/1000\n",
      " - 0s - loss: 302.7905 - val_loss: 291.3617\n",
      "Epoch 13/1000\n",
      " - 0s - loss: 269.5934 - val_loss: 260.8713\n",
      "Epoch 14/1000\n",
      " - 0s - loss: 243.3395 - val_loss: 233.1266\n",
      "Epoch 15/1000\n",
      " - 0s - loss: 217.6031 - val_loss: 208.4505\n",
      "Epoch 16/1000\n",
      " - 0s - loss: 199.0859 - val_loss: 186.2671\n",
      "Epoch 17/1000\n",
      " - 0s - loss: 176.2844 - val_loss: 167.3471\n",
      "Epoch 18/1000\n",
      " - 0s - loss: 158.7301 - val_loss: 149.7904\n",
      "Epoch 19/1000\n",
      " - 0s - loss: 143.4256 - val_loss: 133.6395\n",
      "Epoch 20/1000\n",
      " - 0s - loss: 131.3238 - val_loss: 120.1034\n",
      "Epoch 21/1000\n",
      " - 0s - loss: 119.1136 - val_loss: 110.0457\n",
      "Epoch 22/1000\n",
      " - 0s - loss: 108.5514 - val_loss: 96.6425\n",
      "Epoch 23/1000\n",
      " - 0s - loss: 97.8385 - val_loss: 88.5582\n",
      "Epoch 24/1000\n",
      " - 0s - loss: 93.0915 - val_loss: 77.7802\n",
      "Epoch 25/1000\n",
      " - 0s - loss: 81.0030 - val_loss: 71.7895\n",
      "Epoch 26/1000\n",
      " - 0s - loss: 76.3211 - val_loss: 63.7703\n",
      "Epoch 27/1000\n",
      " - 0s - loss: 70.5597 - val_loss: 57.9530\n",
      "Epoch 28/1000\n",
      " - 0s - loss: 65.7990 - val_loss: 53.1312\n",
      "Epoch 29/1000\n",
      " - 0s - loss: 59.4430 - val_loss: 45.7108\n",
      "Epoch 30/1000\n",
      " - 0s - loss: 56.8086 - val_loss: 45.8994\n",
      "Epoch 31/1000\n",
      " - 0s - loss: 54.6704 - val_loss: 37.4924\n",
      "Epoch 32/1000\n",
      " - 0s - loss: 50.7034 - val_loss: 33.6553\n",
      "Epoch 33/1000\n",
      " - 0s - loss: 45.1506 - val_loss: 31.5190\n",
      "Epoch 34/1000\n",
      " - 0s - loss: 44.3168 - val_loss: 26.9781\n",
      "Epoch 35/1000\n",
      " - 0s - loss: 40.5764 - val_loss: 24.6231\n",
      "Epoch 36/1000\n",
      " - 0s - loss: 40.2884 - val_loss: 22.6011\n",
      "Epoch 37/1000\n",
      " - 0s - loss: 37.2738 - val_loss: 22.1552\n",
      "Epoch 38/1000\n",
      " - 0s - loss: 34.1349 - val_loss: 18.1587\n",
      "Epoch 39/1000\n",
      " - 0s - loss: 33.4452 - val_loss: 17.3390\n",
      "Epoch 40/1000\n",
      " - 0s - loss: 31.1534 - val_loss: 17.4845\n",
      "Epoch 41/1000\n",
      " - 0s - loss: 31.7696 - val_loss: 13.1929\n",
      "Epoch 42/1000\n",
      " - 0s - loss: 31.0528 - val_loss: 15.4548\n",
      "Epoch 43/1000\n",
      " - 0s - loss: 30.0057 - val_loss: 13.0655\n",
      "Epoch 44/1000\n",
      " - 0s - loss: 29.1573 - val_loss: 11.1162\n",
      "Epoch 45/1000\n",
      " - 0s - loss: 27.9074 - val_loss: 10.4387\n",
      "Epoch 46/1000\n",
      " - 0s - loss: 25.5754 - val_loss: 9.4946\n",
      "Epoch 47/1000\n",
      " - 0s - loss: 26.9051 - val_loss: 10.1992\n",
      "Epoch 48/1000\n",
      " - 0s - loss: 24.5682 - val_loss: 7.5916\n",
      "Epoch 49/1000\n",
      " - 0s - loss: 26.0281 - val_loss: 8.8585\n",
      "Epoch 50/1000\n",
      " - 0s - loss: 24.1254 - val_loss: 9.2008\n",
      "Epoch 51/1000\n",
      " - 0s - loss: 22.8465 - val_loss: 7.0667\n",
      "Epoch 52/1000\n",
      " - 0s - loss: 24.6523 - val_loss: 14.6664\n",
      "Epoch 53/1000\n",
      " - 0s - loss: 23.5334 - val_loss: 7.6463\n",
      "Epoch 54/1000\n",
      " - 0s - loss: 22.9595 - val_loss: 7.8079\n",
      "Epoch 55/1000\n",
      " - 0s - loss: 22.2805 - val_loss: 5.3097\n",
      "Epoch 56/1000\n",
      " - 0s - loss: 20.4054 - val_loss: 4.4680\n",
      "Epoch 57/1000\n",
      " - 0s - loss: 21.1668 - val_loss: 6.7368\n",
      "Epoch 58/1000\n",
      " - 0s - loss: 20.5560 - val_loss: 8.5107\n",
      "Epoch 59/1000\n",
      " - 0s - loss: 19.7171 - val_loss: 3.6488\n",
      "Epoch 60/1000\n",
      " - 0s - loss: 20.9017 - val_loss: 8.2366\n",
      "Epoch 61/1000\n",
      " - 0s - loss: 20.2024 - val_loss: 3.6379\n",
      "Epoch 62/1000\n",
      " - 0s - loss: 19.2644 - val_loss: 3.5311\n",
      "Epoch 63/1000\n",
      " - 0s - loss: 18.4245 - val_loss: 8.7967\n",
      "Epoch 64/1000\n",
      " - 0s - loss: 19.6418 - val_loss: 7.9764\n",
      "Epoch 65/1000\n",
      " - 0s - loss: 19.4383 - val_loss: 5.5560\n",
      "Epoch 66/1000\n",
      " - 0s - loss: 18.3804 - val_loss: 5.3891\n",
      "Epoch 67/1000\n",
      " - 0s - loss: 19.5521 - val_loss: 3.8149\n",
      "Epoch 00067: early stopping\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import optimizers\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath=r\"G:\\215\\network_best3.hdf5\", verbose=0, save_best_only=True) # save best model\n",
    "\n",
    "for i in range(5):\n",
    "    print(i)\n",
    "    model_regression= Sequential()\n",
    "    model_regression.add(Dense(150,input_dim=X_train.shape[1], activation='tanh')) # Hidden 1     #  why input_dim=x.shape[1]?  \n",
    "    model_regression.add(Dropout(0.10))\n",
    "    model_regression.add(Dense(100,activation='tanh')) # Hidden 2\n",
    "    model_regression.add(Dropout(0.10))\n",
    "    model_regression.add(Dense(50,activation='tanh'))\n",
    "    model_regression.add(Dropout(0.10))\n",
    "    model_regression.add(Dense(1))\n",
    "    \n",
    "    #model_regression.add(Dense(y_train.shape[2],activation='softmax')) # Output\n",
    "    model_regression.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=5, verbose=1, mode='auto')\n",
    "    \n",
    "    model_regression.fit(X_train, y_train,validation_data=(X_test,y_test),callbacks=[monitor,checkpointer],verbose=2,epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (MSE): 2.2273744394924653\n",
      "Final score (RMSE): 1.4924390907144134\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "model_regression.load_weights(r\"G:\\215\\network_best3.hdf5\")\n",
    "\n",
    "pred = model_regression.predict(X_test)\n",
    "\n",
    "score = metrics.mean_squared_error(pred,y_test)\n",
    "print(\"Final score (MSE): {}\".format(score))\n",
    "\n",
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "print(\"Final score (RMSE): {}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Df = pd.read_csv('updated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Close_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.812500</td>\n",
       "      <td>4.156250</td>\n",
       "      <td>3.812500</td>\n",
       "      <td>4.125000</td>\n",
       "      <td>3675600</td>\n",
       "      <td>4.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.125000</td>\n",
       "      <td>4.125000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.015625</td>\n",
       "      <td>1077600</td>\n",
       "      <td>4.015625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.031250</td>\n",
       "      <td>3.953125</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>437200</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.843750</td>\n",
       "      <td>3.843750</td>\n",
       "      <td>1883600</td>\n",
       "      <td>3.843750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.734375</td>\n",
       "      <td>3.734375</td>\n",
       "      <td>3.390625</td>\n",
       "      <td>3.390625</td>\n",
       "      <td>7931600</td>\n",
       "      <td>3.390625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Open      High       Low     Close   Volume   Close_y\n",
       "0  3.812500  4.156250  3.812500  4.125000  3675600  4.125000\n",
       "1  4.125000  4.125000  4.000000  4.015625  1077600  4.015625\n",
       "2  4.000000  4.031250  3.953125  4.000000   437200  4.000000\n",
       "3  4.000000  4.000000  3.843750  3.843750  1883600  3.843750\n",
       "4  3.734375  3.734375  3.390625  3.390625  7931600  3.390625"
      ]
     },
     "execution_count": 700,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Df=Df.drop(['Unnamed: 0'], axis = 1)\n",
    "Df['Close_y']= Df['Close']\n",
    "Df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Encode a numeric column as zscores\n",
    "def encode_numeric_zscore(df, name, mean=None, sd=None):\n",
    "    if mean is None:\n",
    "        mean = df[name].mean()\n",
    "\n",
    "    if sd is None:\n",
    "        sd = df[name].std()\n",
    "\n",
    "    df[name] = (df[name] - mean) / sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Open', 'High', 'Low', 'Close', 'Volume', 'Close_y'], dtype='object')"
      ]
     },
     "execution_count": 701,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Df=Df[['Open', 'High', 'Low','Volume','Close','Close_y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import sklearn.preprocessing\n",
    "def normalize_data(df):\n",
    "    min_max_scaler = sklearn.preprocessing.MinMaxScaler()\n",
    "    df['Open'] = min_max_scaler.fit_transform(df.Open.values.reshape(-1,1))\n",
    "    df['High'] = min_max_scaler.fit_transform(df.High.values.reshape(-1,1))\n",
    "    df['Low'] = min_max_scaler.fit_transform(df.Low.values.reshape(-1,1))\n",
    "    df['Volume'] = min_max_scaler.fit_transform(df.Volume.values.reshape(-1,1))\n",
    "    df['Close'] = min_max_scaler.fit_transform(df['Close'].values.reshape(-1,1))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raval\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "Df=normalize_data(Df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Close</th>\n",
       "      <th>Close_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.004378</td>\n",
       "      <td>0.006469</td>\n",
       "      <td>0.006934</td>\n",
       "      <td>0.075401</td>\n",
       "      <td>0.007408</td>\n",
       "      <td>4.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.007031</td>\n",
       "      <td>0.006205</td>\n",
       "      <td>0.008535</td>\n",
       "      <td>0.019194</td>\n",
       "      <td>0.006482</td>\n",
       "      <td>4.015625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.005970</td>\n",
       "      <td>0.005413</td>\n",
       "      <td>0.008135</td>\n",
       "      <td>0.005339</td>\n",
       "      <td>0.006350</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.005970</td>\n",
       "      <td>0.005149</td>\n",
       "      <td>0.007201</td>\n",
       "      <td>0.036632</td>\n",
       "      <td>0.005027</td>\n",
       "      <td>3.843750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003714</td>\n",
       "      <td>0.002904</td>\n",
       "      <td>0.003334</td>\n",
       "      <td>0.167478</td>\n",
       "      <td>0.001191</td>\n",
       "      <td>3.390625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Open      High       Low    Volume     Close   Close_y\n",
       "0  0.004378  0.006469  0.006934  0.075401  0.007408  4.125000\n",
       "1  0.007031  0.006205  0.008535  0.019194  0.006482  4.015625\n",
       "2  0.005970  0.005413  0.008135  0.005339  0.006350  4.000000\n",
       "3  0.005970  0.005149  0.007201  0.036632  0.005027  3.843750\n",
       "4  0.003714  0.002904  0.003334  0.167478  0.001191  3.390625"
      ]
     },
     "execution_count": 705,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train=Df[:3074]\n",
    "test=Df[3074:]\n",
    "x_train=train[['Open', 'High', 'Low', 'Volume', 'Close']]\n",
    "x_test=test[['Open', 'High', 'Low', 'Volume', 'Close']]\n",
    "y_train=train['Close_y'].tolist()\n",
    "y_test=test['Close_y'].tolist()\n",
    "x_train=x_train.as_matrix()\n",
    "x_test=x_test.as_matrix()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def to_sequences(seq_size, data1,data2):\n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    for i in range(len(data1)-SEQUENCE_SIZE-1):\n",
    "        #print(i)\n",
    "        window = data1[i:(i+SEQUENCE_SIZE)]\n",
    "        after_window = data2[i+SEQUENCE_SIZE]\n",
    "        window = [[x] for x in window]\n",
    "        #print(\"{} - {}\".format(window,after_window))\n",
    "        x.append(window)\n",
    "        y.append(after_window)\n",
    "        \n",
    "    return np.array(x),np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train: (3066, 7, 1, 5)\n",
      "Shape of x_test: (1310, 7, 1, 5)\n",
      "Shape of y_train: (3066,)\n",
      "Shape of y_test: (1310,)\n"
     ]
    }
   ],
   "source": [
    "SEQUENCE_SIZE = 7\n",
    "x_train,y_train = to_sequences(SEQUENCE_SIZE,x_train,y_train)\n",
    "x_test,y_test = to_sequences(SEQUENCE_SIZE,x_test,y_test)\n",
    "\n",
    "print(\"Shape of x_train: {}\".format(x_train.shape))\n",
    "print(\"Shape of x_test: {}\".format(x_test.shape))\n",
    "print(\"Shape of y_train: {}\".format(y_train.shape))\n",
    "print(\"Shape of y_test: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train=x_train.reshape(3066,7,5)\n",
    "x_test=x_test.reshape(1310,7,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "0\n",
      "Train...\n",
      "Train on 3066 samples, validate on 1310 samples\n",
      "Epoch 1/10\n",
      " - 292s - loss: 162.9618 - val_loss: 9498.4994\n",
      "Epoch 2/10\n",
      " - 5s - loss: 26.1587 - val_loss: 3527.5732\n",
      "Epoch 3/10\n",
      " - 4s - loss: 17.3627 - val_loss: 1730.2013\n",
      "Epoch 4/10\n",
      " - 4s - loss: 11.3442 - val_loss: 329.6103\n",
      "Epoch 5/10\n",
      " - 4s - loss: 6.9778 - val_loss: 20.4097\n",
      "Epoch 6/10\n",
      " - 4s - loss: 4.8154 - val_loss: 259.1655\n",
      "Epoch 7/10\n",
      " - 4s - loss: 4.4174 - val_loss: 227.1077\n",
      "Epoch 8/10\n",
      " - 4s - loss: 3.7452 - val_loss: 441.1601\n",
      "Epoch 9/10\n",
      " - 4s - loss: 3.3543 - val_loss: 560.4616\n",
      "Epoch 10/10\n",
      " - 4s - loss: 3.0891 - val_loss: 542.0368\n",
      "Epoch 00010: early stopping\n",
      "1\n",
      "Train...\n",
      "Train on 3066 samples, validate on 1310 samples\n",
      "Epoch 1/10\n",
      " - 60s - loss: 175.6763 - val_loss: 8088.9447\n",
      "Epoch 2/10\n",
      " - 4s - loss: 27.4309 - val_loss: 3227.0900\n",
      "Epoch 3/10\n",
      " - 4s - loss: 17.5436 - val_loss: 670.3904\n",
      "Epoch 4/10\n",
      " - 4s - loss: 10.8170 - val_loss: 124.4443\n",
      "Epoch 5/10\n",
      " - 4s - loss: 8.4865 - val_loss: 17.2944\n",
      "Epoch 6/10\n",
      " - 4s - loss: 5.9987 - val_loss: 43.1354\n",
      "Epoch 7/10\n",
      " - 4s - loss: 4.9016 - val_loss: 148.3165\n",
      "Epoch 8/10\n",
      " - 4s - loss: 3.6542 - val_loss: 284.2347\n",
      "Epoch 9/10\n",
      " - 4s - loss: 3.6685 - val_loss: 236.8845\n",
      "Epoch 10/10\n",
      " - 4s - loss: 2.9989 - val_loss: 358.0539\n",
      "Epoch 00010: early stopping\n",
      "2\n",
      "Train...\n",
      "Train on 3066 samples, validate on 1310 samples\n",
      "Epoch 1/10\n",
      " - 47s - loss: 179.0168 - val_loss: 3514.9155\n",
      "Epoch 2/10\n",
      " - 4s - loss: 22.6174 - val_loss: 904.3813\n",
      "Epoch 3/10\n",
      " - 4s - loss: 15.8515 - val_loss: 130.3155\n",
      "Epoch 4/10\n",
      " - 4s - loss: 12.1072 - val_loss: 133.6956\n",
      "Epoch 5/10\n",
      " - 4s - loss: 7.7491 - val_loss: 48.3578\n",
      "Epoch 6/10\n",
      " - 4s - loss: 5.4076 - val_loss: 38.2759\n",
      "Epoch 7/10\n",
      " - 4s - loss: 5.1890 - val_loss: 65.5326\n",
      "Epoch 8/10\n",
      " - 4s - loss: 4.4966 - val_loss: 76.9378\n",
      "Epoch 9/10\n",
      " - 4s - loss: 4.7750 - val_loss: 32.0149\n",
      "Epoch 10/10\n",
      " - 4s - loss: 3.6069 - val_loss: 52.7943\n",
      "3\n",
      "Train...\n",
      "Train on 3066 samples, validate on 1310 samples\n",
      "Epoch 1/10\n",
      " - 39s - loss: 173.9326 - val_loss: 10020.8693\n",
      "Epoch 2/10\n",
      " - 4s - loss: 22.2826 - val_loss: 3532.8388\n",
      "Epoch 3/10\n",
      " - 5s - loss: 14.6413 - val_loss: 796.1134\n",
      "Epoch 4/10\n",
      " - 6s - loss: 10.1971 - val_loss: 29.7566\n",
      "Epoch 5/10\n",
      " - 4s - loss: 5.8556 - val_loss: 76.7967\n",
      "Epoch 6/10\n",
      " - 5s - loss: 5.2761 - val_loss: 224.9031\n",
      "Epoch 7/10\n",
      " - 4s - loss: 4.2754 - val_loss: 179.0871\n",
      "Epoch 8/10\n",
      " - 4s - loss: 3.7429 - val_loss: 203.2532\n",
      "Epoch 9/10\n",
      " - 4s - loss: 3.6708 - val_loss: 152.7314\n",
      "Epoch 00009: early stopping\n",
      "4\n",
      "Train...\n",
      "Train on 3066 samples, validate on 1310 samples\n",
      "Epoch 1/10\n",
      " - 39s - loss: 189.7821 - val_loss: 6025.9402\n",
      "Epoch 2/10\n",
      " - 4s - loss: 22.9276 - val_loss: 1212.4218\n",
      "Epoch 3/10\n",
      " - 4s - loss: 18.2656 - val_loss: 434.9474\n",
      "Epoch 4/10\n",
      " - 4s - loss: 11.8911 - val_loss: 52.9199\n",
      "Epoch 5/10\n",
      " - 4s - loss: 7.9547 - val_loss: 82.3448\n",
      "Epoch 6/10\n",
      " - 4s - loss: 6.6386 - val_loss: 140.3238\n",
      "Epoch 7/10\n",
      " - 4s - loss: 5.3113 - val_loss: 177.4971\n",
      "Epoch 8/10\n",
      " - 4s - loss: 4.8898 - val_loss: 250.8275\n",
      "Epoch 9/10\n",
      " - 4s - loss: 4.3016 - val_loss: 104.9957\n",
      "Epoch 00009: early stopping\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import numpy as np\n",
    "from keras import optimizers\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "\n",
    "print('Build model...')\n",
    "checkpointer = ModelCheckpoint(filepath=r\"G:\\215\\lstm.hdf5\", verbose=0, save_best_only=True) # save best model\n",
    "\n",
    "for i in range(5):\n",
    "    print(i)\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(LSTM(64, dropout=0.1, recurrent_dropout=0.1, input_shape=(SEQUENCE_SIZE, 5),activation='relu'))\n",
    "    model.add(Dense(32,activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "    print('Train...')\n",
    "\n",
    "    model.fit(x_train,y_train,validation_data=(x_test,y_test),callbacks=[monitor,checkpointer],verbose=2, epochs=10)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (MSE): 17.294371614013365\n",
      "Final score (RMSE): 4.15865021539602\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "model.load_weights(r\"G:\\215\\lstm.hdf5\")\n",
    "\n",
    "pred = model.predict(x_test)\n",
    "\n",
    "score = metrics.mean_squared_error(pred,y_test)\n",
    "print(\"Final score (MSE): {}\".format(score))\n",
    "\n",
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "print(\"Final score (RMSE): {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAD8CAYAAABthzNFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCCFskgAhhBDCJgkQQgghbPp/6sbEz9CCUkQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d090bc6e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "# Regression chart.\n",
    "def chart_regression(pred,y,sort=True):\n",
    "    t = pd.DataFrame({'pred' : pred, 'y' : y.flatten()})\n",
    "    if sort:\n",
    "        t.sort_values(by=['y'],inplace=True)\n",
    "    a = plt.plot(t['y'].tolist(),label='expected')\n",
    "    b = plt.plot(t['pred'].tolist(),label='prediction')\n",
    "    plt.ylabel('output')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "# Plot the chart\n",
    "chart_regression(pred.flatten(),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "0\n",
      "Train...\n",
      "Train on 3066 samples, validate on 1310 samples\n",
      "Epoch 1/10\n",
      " - 13s - loss: 190.7210 - val_loss: 6594.5243\n",
      "Epoch 2/10\n",
      " - 2s - loss: 30.2974 - val_loss: 2718.5426\n",
      "Epoch 3/10\n",
      " - 1s - loss: 22.0634 - val_loss: 1125.7350\n",
      "Epoch 4/10\n",
      " - 1s - loss: 16.2243 - val_loss: 46.5027\n",
      "Epoch 5/10\n",
      " - 1s - loss: 11.9850 - val_loss: 96.5365\n",
      "Epoch 6/10\n",
      " - 1s - loss: 9.9354 - val_loss: 179.8258\n",
      "Epoch 7/10\n",
      " - 1s - loss: 8.9891 - val_loss: 242.6054\n",
      "Epoch 8/10\n",
      " - 1s - loss: 7.8102 - val_loss: 186.1185\n",
      "Epoch 9/10\n",
      " - 1s - loss: 7.2466 - val_loss: 261.3347\n",
      "Epoch 00009: early stopping\n",
      "1\n",
      "Train...\n",
      "Train on 3066 samples, validate on 1310 samples\n",
      "Epoch 1/10\n",
      " - 12s - loss: 167.6698 - val_loss: 6083.4564\n",
      "Epoch 2/10\n",
      " - 1s - loss: 22.9553 - val_loss: 428.9266\n",
      "Epoch 3/10\n",
      " - 2s - loss: 16.1709 - val_loss: 62.0228\n",
      "Epoch 4/10\n",
      " - 1s - loss: 13.8783 - val_loss: 74.9764\n",
      "Epoch 5/10\n",
      " - 1s - loss: 11.4500 - val_loss: 131.9446\n",
      "Epoch 6/10\n",
      " - 1s - loss: 9.9438 - val_loss: 282.6166\n",
      "Epoch 7/10\n",
      " - 1s - loss: 9.1955 - val_loss: 345.1858\n",
      "Epoch 8/10\n",
      " - 1s - loss: 7.5476 - val_loss: 327.1309\n",
      "Epoch 00008: early stopping\n",
      "2\n",
      "Train...\n",
      "Train on 3066 samples, validate on 1310 samples\n",
      "Epoch 1/10\n",
      " - 12s - loss: 181.5017 - val_loss: 6117.7183\n",
      "Epoch 2/10\n",
      " - 1s - loss: 28.6634 - val_loss: 2076.6651\n",
      "Epoch 3/10\n",
      " - 1s - loss: 21.8838 - val_loss: 381.6489\n",
      "Epoch 4/10\n",
      " - 1s - loss: 17.4627 - val_loss: 193.9752\n",
      "Epoch 5/10\n",
      " - 1s - loss: 12.0277 - val_loss: 144.4395\n",
      "Epoch 6/10\n",
      " - 1s - loss: 10.7492 - val_loss: 153.8605\n",
      "Epoch 7/10\n",
      " - 1s - loss: 9.6322 - val_loss: 269.4939\n",
      "Epoch 8/10\n",
      " - 1s - loss: 8.3165 - val_loss: 311.0997\n",
      "Epoch 9/10\n",
      " - 1s - loss: 8.0350 - val_loss: 222.7994\n",
      "Epoch 10/10\n",
      " - 1s - loss: 6.9236 - val_loss: 548.4742\n",
      "Epoch 00010: early stopping\n",
      "3\n",
      "Train...\n",
      "Train on 3066 samples, validate on 1310 samples\n",
      "Epoch 1/10\n",
      " - 13s - loss: 189.7790 - val_loss: 4333.8601\n",
      "Epoch 2/10\n",
      " - 1s - loss: 31.1035 - val_loss: 1803.4605\n",
      "Epoch 3/10\n",
      " - 1s - loss: 22.8053 - val_loss: 521.7272\n",
      "Epoch 4/10\n",
      " - 1s - loss: 18.4828 - val_loss: 339.4062\n",
      "Epoch 5/10\n",
      " - 1s - loss: 16.1361 - val_loss: 235.5845\n",
      "Epoch 6/10\n",
      " - 1s - loss: 12.8395 - val_loss: 79.1424\n",
      "Epoch 7/10\n",
      " - 1s - loss: 11.2758 - val_loss: 87.3293\n",
      "Epoch 8/10\n",
      " - 1s - loss: 9.6348 - val_loss: 39.2320\n",
      "Epoch 9/10\n",
      " - 1s - loss: 9.1504 - val_loss: 34.0175\n",
      "Epoch 10/10\n",
      " - 1s - loss: 8.9803 - val_loss: 60.0394\n",
      "4\n",
      "Train...\n",
      "Train on 3066 samples, validate on 1310 samples\n",
      "Epoch 1/10\n",
      " - 13s - loss: 167.8035 - val_loss: 4220.7779\n",
      "Epoch 2/10\n",
      " - 2s - loss: 30.9782 - val_loss: 1117.5111\n",
      "Epoch 3/10\n",
      " - 2s - loss: 19.1048 - val_loss: 852.3727\n",
      "Epoch 4/10\n",
      " - 2s - loss: 16.1813 - val_loss: 29.1402\n",
      "Epoch 5/10\n",
      " - 2s - loss: 12.9292 - val_loss: 41.4692\n",
      "Epoch 6/10\n",
      " - 1s - loss: 10.0990 - val_loss: 207.7213\n",
      "Epoch 7/10\n",
      " - 2s - loss: 9.4109 - val_loss: 200.1051\n",
      "Epoch 8/10\n",
      " - 1s - loss: 8.3600 - val_loss: 190.5999\n",
      "Epoch 9/10\n",
      " - 1s - loss: 7.8217 - val_loss: 327.6354\n",
      "Epoch 00009: early stopping\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import numpy as np\n",
    "from keras import optimizers\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "\n",
    "print('Build model...')\n",
    "checkpointer = ModelCheckpoint(filepath=r\"G:\\215\\lstm1.hdf5\", verbose=0, save_best_only=True) # save best model\n",
    "\n",
    "for i in range(5):\n",
    "    print(i)\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(LSTM(64, dropout=0.1, recurrent_dropout=0.1, input_shape=(SEQUENCE_SIZE, 5),activation = 'relu'))\n",
    "    model.add(Dropout(0.10))\n",
    "    model.add(Dense(32,activation='relu'))\n",
    "    model.add(Dropout(0.10))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "    print('Train...')\n",
    "\n",
    "    model.fit(x_train,y_train,validation_data=(x_test,y_test),callbacks=[monitor,checkpointer],verbose=2, epochs=10)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (MSE): 29.140187051528383\n",
      "Final score (RMSE): 5.398165156007028\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "model.load_weights(r\"G:\\215\\lstm1.hdf5\")\n",
    "\n",
    "pred = model.predict(x_test)\n",
    "\n",
    "score = metrics.mean_squared_error(pred,y_test)\n",
    "print(\"Final score (MSE): {}\".format(score))\n",
    "\n",
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "print(\"Final score (RMSE): {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "0\n",
      "Train...\n",
      "Train on 3066 samples, validate on 1310 samples\n",
      "Epoch 1/10\n",
      " - 14s - loss: 257.5708 - val_loss: 4630.8772\n",
      "Epoch 2/10\n",
      " - 1s - loss: 195.7378 - val_loss: 4400.3464\n",
      "Epoch 3/10\n",
      " - 1s - loss: 169.3711 - val_loss: 4217.5311\n",
      "Epoch 4/10\n",
      " - 1s - loss: 151.2173 - val_loss: 4062.4100\n",
      "Epoch 5/10\n",
      " - 1s - loss: 138.8915 - val_loss: 3921.5321\n",
      "Epoch 6/10\n",
      " - 1s - loss: 131.2110 - val_loss: 3812.4155\n",
      "Epoch 7/10\n",
      " - 1s - loss: 126.2159 - val_loss: 3725.8160\n",
      "Epoch 8/10\n",
      " - 1s - loss: 123.9752 - val_loss: 3666.4668\n",
      "Epoch 9/10\n",
      " - 1s - loss: 122.4800 - val_loss: 3622.4602\n",
      "Epoch 10/10\n",
      " - 1s - loss: 122.3110 - val_loss: 3590.9575\n",
      "1\n",
      "Train...\n",
      "Train on 3066 samples, validate on 1310 samples\n",
      "Epoch 1/10\n",
      " - 13s - loss: 273.3720 - val_loss: 4702.0050\n",
      "Epoch 2/10\n",
      " - 2s - loss: 208.4342 - val_loss: 4503.7395\n",
      "Epoch 3/10\n",
      " - 2s - loss: 182.8519 - val_loss: 4340.8029\n",
      "Epoch 4/10\n",
      " - 2s - loss: 165.2096 - val_loss: 4202.3315\n",
      "Epoch 5/10\n",
      " - 2s - loss: 152.1955 - val_loss: 4081.9469\n",
      "Epoch 6/10\n",
      " - 2s - loss: 141.5844 - val_loss: 3969.7617\n",
      "Epoch 7/10\n",
      " - 2s - loss: 133.9655 - val_loss: 3865.1325\n",
      "Epoch 8/10\n",
      " - 1s - loss: 129.5006 - val_loss: 3785.6249\n",
      "Epoch 9/10\n",
      " - 1s - loss: 126.8782 - val_loss: 3723.0524\n",
      "Epoch 10/10\n",
      " - 1s - loss: 124.7317 - val_loss: 3672.0292\n",
      "2\n",
      "Train...\n",
      "Train on 3066 samples, validate on 1310 samples\n",
      "Epoch 1/10\n",
      " - 13s - loss: 259.8968 - val_loss: 4651.0941\n",
      "Epoch 2/10\n",
      " - 1s - loss: 202.0183 - val_loss: 4462.0326\n",
      "Epoch 3/10\n",
      " - 1s - loss: 178.5408 - val_loss: 4306.3332\n",
      "Epoch 4/10\n",
      " - 2s - loss: 160.1684 - val_loss: 4145.2753\n",
      "Epoch 5/10\n",
      " - 1s - loss: 145.1476 - val_loss: 4002.1085\n",
      "Epoch 6/10\n",
      " - 1s - loss: 136.0527 - val_loss: 3889.7248\n",
      "Epoch 7/10\n",
      " - 1s - loss: 130.1119 - val_loss: 3804.7170\n",
      "Epoch 8/10\n",
      " - 1s - loss: 126.2789 - val_loss: 3734.7340\n",
      "Epoch 9/10\n",
      " - 1s - loss: 124.6863 - val_loss: 3679.4604\n",
      "Epoch 10/10\n",
      " - 1s - loss: 123.2590 - val_loss: 3638.7573\n",
      "3\n",
      "Train...\n",
      "Train on 3066 samples, validate on 1310 samples\n",
      "Epoch 1/10\n",
      " - 14s - loss: 271.0532 - val_loss: 4721.2275\n",
      "Epoch 2/10\n",
      " - 2s - loss: 206.7434 - val_loss: 4467.1229\n",
      "Epoch 3/10\n",
      " - 2s - loss: 176.1812 - val_loss: 4266.9563\n",
      "Epoch 4/10\n",
      " - 2s - loss: 155.8082 - val_loss: 4102.4874\n",
      "Epoch 5/10\n",
      " - 2s - loss: 141.9417 - val_loss: 3967.0842\n",
      "Epoch 6/10\n",
      " - 2s - loss: 133.2940 - val_loss: 3857.2696\n",
      "Epoch 7/10\n",
      " - 2s - loss: 128.6644 - val_loss: 3770.5189\n",
      "Epoch 8/10\n",
      " - 1s - loss: 125.3048 - val_loss: 3702.3381\n",
      "Epoch 9/10\n",
      " - 2s - loss: 123.3824 - val_loss: 3650.6546\n",
      "Epoch 10/10\n",
      " - 2s - loss: 122.7179 - val_loss: 3613.7394\n",
      "4\n",
      "Train...\n",
      "Train on 3066 samples, validate on 1310 samples\n",
      "Epoch 1/10\n",
      " - 13s - loss: 254.9281 - val_loss: 4603.3262\n",
      "Epoch 2/10\n",
      " - 1s - loss: 189.7566 - val_loss: 4347.3832\n",
      "Epoch 3/10\n",
      " - 1s - loss: 162.1363 - val_loss: 4147.6347\n",
      "Epoch 4/10\n",
      " - 1s - loss: 145.0581 - val_loss: 3981.6630\n",
      "Epoch 5/10\n",
      " - 1s - loss: 133.9110 - val_loss: 3844.0083\n",
      "Epoch 6/10\n",
      " - 1s - loss: 126.9822 - val_loss: 3732.9491\n",
      "Epoch 7/10\n",
      " - 1s - loss: 124.1486 - val_loss: 3656.5815\n",
      "Epoch 8/10\n",
      " - 1s - loss: 122.5545 - val_loss: 3609.4325\n",
      "Epoch 9/10\n",
      " - 1s - loss: 122.7984 - val_loss: 3577.6410\n",
      "Epoch 10/10\n",
      " - 2s - loss: 121.3910 - val_loss: 3558.3425\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import numpy as np\n",
    "from keras import optimizers\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "\n",
    "print('Build model...')\n",
    "checkpointer = ModelCheckpoint(filepath=r\"G:\\215\\lstm2.hdf5\", verbose=0, save_best_only=True) # save best model\n",
    "\n",
    "for i in range(5):\n",
    "    print(i)\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(LSTM(64, dropout=0.1, recurrent_dropout=0.1, input_shape=(SEQUENCE_SIZE, 5),activation = 'sigmoid'))\n",
    "    model.add(Dropout(0.10))\n",
    "    model.add(Dense(32,activation='sigmoid'))\n",
    "    model.add(Dropout(0.10))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "    print('Train...')\n",
    "\n",
    "    model.fit(x_train,y_train,validation_data=(x_test,y_test),callbacks=[monitor,checkpointer],verbose=2, epochs=10)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (MSE): 3558.3425460084013\n",
      "Final score (RMSE): 59.65184444766483\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "model.load_weights(r\"G:\\215\\lstm2.hdf5\")\n",
    "\n",
    "pred = model.predict(x_test)\n",
    "\n",
    "score = metrics.mean_squared_error(pred,y_test)\n",
    "print(\"Final score (MSE): {}\".format(score))\n",
    "\n",
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "print(\"Final score (RMSE): {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "0\n",
      "Train...\n",
      "Train on 3066 samples, validate on 1310 samples\n",
      "Epoch 1/10\n",
      " - 18s - loss: 206.8799 - val_loss: 4029.4484\n",
      "Epoch 2/10\n",
      " - 2s - loss: 132.3797 - val_loss: 3785.2597\n",
      "Epoch 3/10\n",
      " - 2s - loss: 104.3038 - val_loss: 3494.9309\n",
      "Epoch 4/10\n",
      " - 2s - loss: 79.7939 - val_loss: 3230.5491\n",
      "Epoch 5/10\n",
      " - 2s - loss: 63.2259 - val_loss: 3009.6410\n",
      "Epoch 6/10\n",
      " - 2s - loss: 50.0392 - val_loss: 2816.2849\n",
      "Epoch 7/10\n",
      " - 2s - loss: 39.0145 - val_loss: 2646.9907\n",
      "Epoch 8/10\n",
      " - 2s - loss: 31.5796 - val_loss: 2500.1873\n",
      "Epoch 9/10\n",
      " - 2s - loss: 25.9416 - val_loss: 2373.5227\n",
      "Epoch 10/10\n",
      " - 2s - loss: 21.3425 - val_loss: 2264.9020\n",
      "1\n",
      "Train...\n",
      "Train on 3066 samples, validate on 1310 samples\n",
      "Epoch 1/10\n",
      " - 17s - loss: 205.0110 - val_loss: 3996.6981\n",
      "Epoch 2/10\n",
      " - 2s - loss: 130.5194 - val_loss: 3756.5225\n",
      "Epoch 3/10\n",
      " - 2s - loss: 98.9043 - val_loss: 3441.3028\n",
      "Epoch 4/10\n",
      " - 2s - loss: 76.1278 - val_loss: 3179.8630\n",
      "Epoch 5/10\n",
      " - 2s - loss: 59.7123 - val_loss: 2964.5228\n",
      "Epoch 6/10\n",
      " - 2s - loss: 47.4388 - val_loss: 2776.4190\n",
      "Epoch 7/10\n",
      " - 2s - loss: 37.7788 - val_loss: 2613.6790\n",
      "Epoch 8/10\n",
      " - 2s - loss: 30.3280 - val_loss: 2465.7686\n",
      "Epoch 9/10\n",
      " - 2s - loss: 25.5575 - val_loss: 2343.3070\n",
      "Epoch 10/10\n",
      " - 2s - loss: 20.1048 - val_loss: 2232.6677\n",
      "2\n",
      "Train...\n",
      "Train on 3066 samples, validate on 1310 samples\n",
      "Epoch 1/10\n",
      " - 16s - loss: 225.1833 - val_loss: 4161.4446\n",
      "Epoch 2/10\n",
      " - 2s - loss: 140.6938 - val_loss: 3873.5428\n",
      "Epoch 3/10\n",
      " - 2s - loss: 121.6080 - val_loss: 3652.5500\n",
      "Epoch 4/10\n",
      " - 2s - loss: 90.7330 - val_loss: 3368.2366\n",
      "Epoch 5/10\n",
      " - 2s - loss: 71.5767 - val_loss: 3136.8024\n",
      "Epoch 6/10\n",
      " - 2s - loss: 56.9282 - val_loss: 2931.6736\n",
      "Epoch 7/10\n",
      " - 2s - loss: 45.7587 - val_loss: 2750.0456\n",
      "Epoch 8/10\n",
      " - 2s - loss: 36.6835 - val_loss: 2594.1319\n",
      "Epoch 9/10\n",
      " - 2s - loss: 30.1421 - val_loss: 2458.3205\n",
      "Epoch 10/10\n",
      " - 2s - loss: 24.4910 - val_loss: 2340.0706\n",
      "3\n",
      "Train...\n",
      "Train on 3066 samples, validate on 1310 samples\n",
      "Epoch 1/10\n",
      " - 16s - loss: 206.2748 - val_loss: 4091.2075\n",
      "Epoch 2/10\n",
      " - 2s - loss: 135.0860 - val_loss: 3825.2996\n",
      "Epoch 3/10\n",
      " - 2s - loss: 111.9265 - val_loss: 3564.1846\n",
      "Epoch 4/10\n",
      " - 2s - loss: 84.5791 - val_loss: 3294.9530\n",
      "Epoch 5/10\n",
      " - 2s - loss: 66.6645 - val_loss: 3064.3711\n",
      "Epoch 6/10\n",
      " - 2s - loss: 53.5917 - val_loss: 2875.8067\n",
      "Epoch 7/10\n",
      " - 2s - loss: 43.0618 - val_loss: 2704.2584\n",
      "Epoch 8/10\n",
      " - 2s - loss: 34.6736 - val_loss: 2550.3214\n",
      "Epoch 9/10\n",
      " - 2s - loss: 27.7002 - val_loss: 2419.4856\n",
      "Epoch 10/10\n",
      " - 2s - loss: 23.2033 - val_loss: 2304.1531\n",
      "4\n",
      "Train...\n",
      "Train on 3066 samples, validate on 1310 samples\n",
      "Epoch 1/10\n",
      " - 19s - loss: 211.6331 - val_loss: 4003.0614\n",
      "Epoch 2/10\n",
      " - 2s - loss: 131.9142 - val_loss: 3761.6446\n",
      "Epoch 3/10\n",
      " - 2s - loss: 108.6977 - val_loss: 3502.4253\n",
      "Epoch 4/10\n",
      " - 2s - loss: 79.8559 - val_loss: 3225.7673\n",
      "Epoch 5/10\n",
      " - 2s - loss: 61.7017 - val_loss: 2993.5748\n",
      "Epoch 6/10\n",
      " - 2s - loss: 48.8556 - val_loss: 2800.6625\n",
      "Epoch 7/10\n",
      " - 2s - loss: 38.9808 - val_loss: 2629.5004\n",
      "Epoch 8/10\n",
      " - 2s - loss: 30.9884 - val_loss: 2482.4527\n",
      "Epoch 9/10\n",
      " - 2s - loss: 25.2791 - val_loss: 2354.4275\n",
      "Epoch 10/10\n",
      " - 2s - loss: 20.6763 - val_loss: 2246.7380\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import numpy as np\n",
    "from keras import optimizers\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "\n",
    "print('Build model...')\n",
    "checkpointer = ModelCheckpoint(filepath=r\"G:\\215\\lstm4.hdf5\", verbose=0, save_best_only=True) # save best model\n",
    "\n",
    "for i in range(5):\n",
    "    print(i)\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(LSTM(64, dropout=0.1, recurrent_dropout=0.1, input_shape=(SEQUENCE_SIZE, 5),activation = 'tanh'))\n",
    "    model.add(Dropout(0.10))\n",
    "    model.add(Dense(32,activation='tanh'))\n",
    "    model.add(Dropout(0.10))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "    print('Train...')\n",
    "\n",
    "    model.fit(x_train,y_train,validation_data=(x_test,y_test),callbacks=[monitor,checkpointer],verbose=2, epochs=10)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (MSE): 2232.667701339635\n",
      "Final score (RMSE): 47.25111322857521\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "model.load_weights(r\"G:\\215\\lstm4.hdf5\")\n",
    "\n",
    "pred = model.predict(x_test)\n",
    "\n",
    "score = metrics.mean_squared_error(pred,y_test)\n",
    "print(\"Final score (MSE): {}\".format(score))\n",
    "\n",
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "print(\"Final score (RMSE): {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "0\n",
      "Train...\n",
      "Train on 3066 samples, validate on 1310 samples\n",
      "Epoch 1/10\n",
      " - 16s - loss: nan - val_loss: nan\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raval\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:538: RuntimeWarning: invalid value encountered in less\n",
      "  if self.monitor_op(current - self.min_delta, self.best):\n",
      "C:\\Users\\raval\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:434: RuntimeWarning: invalid value encountered in less\n",
      "  if self.monitor_op(current, self.best):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 2s - loss: nan - val_loss: nan\n",
      "Epoch 3/10\n",
      " - 2s - loss: nan - val_loss: nan\n",
      "Epoch 4/10\n",
      " - 2s - loss: nan - val_loss: nan\n",
      "Epoch 5/10\n",
      " - 2s - loss: nan - val_loss: nan\n",
      "Epoch 00005: early stopping\n",
      "1\n",
      "Train...\n",
      "Train on 3066 samples, validate on 1310 samples\n",
      "Epoch 1/10\n",
      " - 17s - loss: nan - val_loss: nan\n",
      "Epoch 2/10\n",
      " - 2s - loss: nan - val_loss: nan\n",
      "Epoch 3/10\n",
      " - 2s - loss: nan - val_loss: nan\n",
      "Epoch 4/10\n",
      " - 2s - loss: nan - val_loss: nan\n",
      "Epoch 5/10\n",
      " - 2s - loss: nan - val_loss: nan\n",
      "Epoch 00005: early stopping\n",
      "2\n",
      "Train...\n",
      "Train on 3066 samples, validate on 1310 samples\n",
      "Epoch 1/10\n",
      " - 21s - loss: nan - val_loss: nan\n",
      "Epoch 2/10\n",
      " - 2s - loss: nan - val_loss: nan\n",
      "Epoch 3/10\n",
      " - 2s - loss: nan - val_loss: nan\n",
      "Epoch 4/10\n",
      " - 2s - loss: nan - val_loss: nan\n",
      "Epoch 5/10\n",
      " - 2s - loss: nan - val_loss: nan\n",
      "Epoch 00005: early stopping\n",
      "3\n",
      "Train...\n",
      "Train on 3066 samples, validate on 1310 samples\n",
      "Epoch 1/10\n",
      " - 19s - loss: nan - val_loss: nan\n",
      "Epoch 2/10\n",
      " - 2s - loss: nan - val_loss: nan\n",
      "Epoch 3/10\n",
      " - 2s - loss: nan - val_loss: nan\n",
      "Epoch 4/10\n",
      " - 2s - loss: nan - val_loss: nan\n",
      "Epoch 5/10\n",
      " - 2s - loss: nan - val_loss: nan\n",
      "Epoch 00005: early stopping\n",
      "4\n",
      "Train...\n",
      "Train on 3066 samples, validate on 1310 samples\n",
      "Epoch 1/10\n",
      " - 17s - loss: nan - val_loss: nan\n",
      "Epoch 2/10\n",
      " - 2s - loss: nan - val_loss: nan\n",
      "Epoch 3/10\n",
      " - 2s - loss: nan - val_loss: nan\n",
      "Epoch 4/10\n",
      " - 2s - loss: nan - val_loss: nan\n",
      "Epoch 5/10\n",
      " - 2s - loss: nan - val_loss: nan\n",
      "Epoch 00005: early stopping\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import numpy as np\n",
    "from keras import optimizers\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "\n",
    "print('Build model...')\n",
    "checkpointer = ModelCheckpoint(filepath=r\"G:\\215\\lstm4.hdf5\", verbose=0, save_best_only=True) # save best model\n",
    "\n",
    "for i in range(5):\n",
    "    print(i)\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(LSTM(64, dropout=0.1, recurrent_dropout=0.1, input_shape=(SEQUENCE_SIZE, 5),activation = 'relu'))\n",
    "    model.add(Dropout(0.10))\n",
    "    model.add(Dense(32,activation='relu'))\n",
    "    model.add(Dropout(0.10))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer='sgd')\n",
    "\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "    print('Train...')\n",
    "\n",
    "    model.fit(x_train,y_train,validation_data=(x_test,y_test),callbacks=[monitor,checkpointer],verbose=2, epochs=10)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (MSE): 718.9079293335528\n",
      "Final score (RMSE): 26.812458472388407\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "model.load_weights(r\"G:\\215\\lstm4.hdf5\")\n",
    "\n",
    "pred = model.predict(x_test)\n",
    "\n",
    "score = metrics.mean_squared_error(pred,y_test)\n",
    "print(\"Final score (MSE): {}\".format(score))\n",
    "\n",
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "print(\"Final score (RMSE): {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "0\n",
      "Train...\n",
      "Train on 3066 samples, validate on 1310 samples\n",
      "Epoch 1/10\n",
      " - 18s - loss: 102.6412 - val_loss: 2718.7728\n",
      "Epoch 2/10\n",
      " - 2s - loss: 29.8759 - val_loss: 1007.2631\n",
      "Epoch 3/10\n",
      " - 2s - loss: 23.7752 - val_loss: 517.2078\n",
      "Epoch 4/10\n",
      " - 2s - loss: 19.1857 - val_loss: 223.9311\n",
      "Epoch 5/10\n",
      " - 2s - loss: 15.7664 - val_loss: 123.5365\n",
      "Epoch 6/10\n",
      " - 2s - loss: 13.9829 - val_loss: 51.4388\n",
      "Epoch 7/10\n",
      " - 2s - loss: 12.4637 - val_loss: 34.7304\n",
      "Epoch 8/10\n",
      " - 2s - loss: 11.1907 - val_loss: 60.3123\n",
      "Epoch 9/10\n",
      " - 2s - loss: 11.0220 - val_loss: 17.1603\n",
      "Epoch 10/10\n",
      " - 2s - loss: 9.2321 - val_loss: 51.8122\n",
      "1\n",
      "Train...\n",
      "Train on 3066 samples, validate on 1310 samples\n",
      "Epoch 1/10\n",
      " - 17s - loss: 108.3761 - val_loss: 2842.5049\n",
      "Epoch 2/10\n",
      " - 2s - loss: 28.9409 - val_loss: 1152.8322\n",
      "Epoch 3/10\n",
      " - 2s - loss: 25.0525 - val_loss: 848.3005\n",
      "Epoch 4/10\n",
      " - 2s - loss: 19.1397 - val_loss: 58.9514\n",
      "Epoch 5/10\n",
      " - 2s - loss: 14.8415 - val_loss: 47.7229\n",
      "Epoch 6/10\n",
      " - 2s - loss: 13.6184 - val_loss: 170.9202\n",
      "Epoch 7/10\n",
      " - 2s - loss: 12.0581 - val_loss: 55.1882\n",
      "Epoch 8/10\n",
      " - 2s - loss: 11.6037 - val_loss: 153.1750\n",
      "Epoch 9/10\n",
      " - 2s - loss: 9.4583 - val_loss: 22.4777\n",
      "Epoch 10/10\n",
      " - 2s - loss: 9.4547 - val_loss: 306.6760\n",
      "2\n",
      "Train...\n",
      "Train on 3066 samples, validate on 1310 samples\n",
      "Epoch 1/10\n",
      " - 18s - loss: 103.9260 - val_loss: 7905.0988\n",
      "Epoch 2/10\n",
      " - 2s - loss: 29.5671 - val_loss: 4225.4136\n",
      "Epoch 3/10\n",
      " - 2s - loss: 22.5143 - val_loss: 730.0166\n",
      "Epoch 4/10\n",
      " - 2s - loss: 18.2634 - val_loss: 35.3937\n",
      "Epoch 5/10\n",
      " - 2s - loss: 14.1550 - val_loss: 94.3436\n",
      "Epoch 6/10\n",
      " - 2s - loss: 10.3291 - val_loss: 244.7929\n",
      "Epoch 7/10\n",
      " - 2s - loss: 9.5498 - val_loss: 51.9000\n",
      "Epoch 8/10\n",
      " - 2s - loss: 9.6898 - val_loss: 401.2020\n",
      "Epoch 9/10\n",
      " - 2s - loss: 8.8947 - val_loss: 198.2451\n",
      "Epoch 00009: early stopping\n",
      "3\n",
      "Train...\n",
      "Train on 3066 samples, validate on 1310 samples\n",
      "Epoch 1/10\n",
      " - 18s - loss: 122.2075 - val_loss: 2030.8657\n",
      "Epoch 2/10\n",
      " - 2s - loss: 30.0601 - val_loss: 2825.6718\n",
      "Epoch 3/10\n",
      " - 2s - loss: 24.3909 - val_loss: 1486.4316\n",
      "Epoch 4/10\n",
      " - 2s - loss: 21.6109 - val_loss: 682.2844\n",
      "Epoch 5/10\n",
      " - 2s - loss: 19.1203 - val_loss: 209.1597\n",
      "Epoch 6/10\n",
      " - 2s - loss: 15.8608 - val_loss: 66.2892\n",
      "Epoch 7/10\n",
      " - 2s - loss: 13.7449 - val_loss: 107.8633\n",
      "Epoch 8/10\n",
      " - 2s - loss: 11.3809 - val_loss: 143.2294\n",
      "Epoch 9/10\n",
      " - 2s - loss: 11.0661 - val_loss: 42.6947\n",
      "Epoch 10/10\n",
      " - 2s - loss: 10.0973 - val_loss: 26.4600\n",
      "4\n",
      "Train...\n",
      "Train on 3066 samples, validate on 1310 samples\n",
      "Epoch 1/10\n",
      " - 18s - loss: 99.0336 - val_loss: 6032.0233\n",
      "Epoch 2/10\n",
      " - 2s - loss: 28.4617 - val_loss: 1896.9792\n",
      "Epoch 3/10\n",
      " - 2s - loss: 25.0616 - val_loss: 1363.6826\n",
      "Epoch 4/10\n",
      " - 2s - loss: 21.4025 - val_loss: 41.5915\n",
      "Epoch 5/10\n",
      " - 2s - loss: 14.6700 - val_loss: 26.6594\n",
      "Epoch 6/10\n",
      " - 2s - loss: 12.4975 - val_loss: 255.4659\n",
      "Epoch 7/10\n",
      " - 2s - loss: 11.0158 - val_loss: 242.9082\n",
      "Epoch 8/10\n",
      " - 2s - loss: 9.9774 - val_loss: 126.1047\n",
      "Epoch 9/10\n",
      " - 2s - loss: 9.1763 - val_loss: 344.1754\n",
      "Epoch 10/10\n",
      " - 2s - loss: 8.5629 - val_loss: 629.4496\n",
      "Epoch 00010: early stopping\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import numpy as np\n",
    "from keras import optimizers\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "\n",
    "print('Build model...')\n",
    "checkpointer = ModelCheckpoint(filepath=r\"G:\\215\\lstm5.hdf5\", verbose=0, save_best_only=True) # save best model\n",
    "\n",
    "for i in range(5):\n",
    "    print(i)\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(LSTM(64, dropout=0.1, recurrent_dropout=0.1, input_shape=(SEQUENCE_SIZE, 5),activation = 'relu'))\n",
    "    model.add(Dropout(0.10))\n",
    "    model.add(Dense(32,activation='relu'))\n",
    "    model.add(Dropout(0.10))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer='rmsprop')\n",
    "\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "    print('Train...')\n",
    "\n",
    "    model.fit(x_train,y_train,validation_data=(x_test,y_test),callbacks=[monitor,checkpointer],verbose=2, epochs=10)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (MSE): 17.160293217734637\n",
      "Final score (RMSE): 4.142498427004486\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "model.load_weights(r\"G:\\215\\lstm5.hdf5\")\n",
    "\n",
    "pred = model.predict(x_test)\n",
    "\n",
    "score = metrics.mean_squared_error(pred,y_test)\n",
    "print(\"Final score (MSE): {}\".format(score))\n",
    "\n",
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "print(\"Final score (RMSE): {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "0\n",
      "Train...\n",
      "Train on 3066 samples, validate on 1310 samples\n",
      "Epoch 1/10\n",
      " - 18s - loss: 143.4978 - val_loss: 3873.3042\n",
      "Epoch 2/10\n",
      " - 1s - loss: 32.9452 - val_loss: 2085.1339\n",
      "Epoch 3/10\n",
      " - 1s - loss: 28.8843 - val_loss: 733.4388\n",
      "Epoch 4/10\n",
      " - 1s - loss: 22.9301 - val_loss: 785.2578\n",
      "Epoch 5/10\n",
      " - 1s - loss: 17.7725 - val_loss: 68.0797\n",
      "Epoch 6/10\n",
      " - 1s - loss: 14.7564 - val_loss: 127.8297\n",
      "Epoch 7/10\n",
      " - 1s - loss: 13.2198 - val_loss: 149.4379\n",
      "Epoch 8/10\n",
      " - 1s - loss: 10.9497 - val_loss: 133.3829\n",
      "Epoch 9/10\n",
      " - 1s - loss: 9.5956 - val_loss: 386.6356\n",
      "Epoch 10/10\n",
      " - 1s - loss: 9.5406 - val_loss: 392.5920\n",
      "Epoch 00010: early stopping\n",
      "1\n",
      "Train...\n",
      "Train on 3066 samples, validate on 1310 samples\n",
      "Epoch 1/10\n",
      " - 17s - loss: 151.0548 - val_loss: 10723.1446\n",
      "Epoch 2/10\n",
      " - 1s - loss: 33.9653 - val_loss: 1918.0189\n",
      "Epoch 3/10\n",
      " - 1s - loss: 28.9045 - val_loss: 1268.8261\n",
      "Epoch 4/10\n",
      " - 1s - loss: 25.3543 - val_loss: 623.2145\n",
      "Epoch 5/10\n",
      " - 1s - loss: 19.3707 - val_loss: 32.1566\n",
      "Epoch 6/10\n",
      " - 1s - loss: 17.2085 - val_loss: 116.5545\n",
      "Epoch 7/10\n",
      " - 1s - loss: 15.6325 - val_loss: 83.2135\n",
      "Epoch 8/10\n",
      " - 1s - loss: 11.9481 - val_loss: 305.6606\n",
      "Epoch 9/10\n",
      " - 1s - loss: 11.4878 - val_loss: 183.6251\n",
      "Epoch 10/10\n",
      " - 2s - loss: 10.1747 - val_loss: 356.7322\n",
      "Epoch 00010: early stopping\n",
      "2\n",
      "Train...\n",
      "Train on 3066 samples, validate on 1310 samples\n",
      "Epoch 1/10\n",
      " - 18s - loss: 144.2696 - val_loss: 958.9449\n",
      "Epoch 2/10\n",
      " - 1s - loss: 32.4277 - val_loss: 465.3832\n",
      "Epoch 3/10\n",
      " - 1s - loss: 26.5444 - val_loss: 130.6295\n",
      "Epoch 4/10\n",
      " - 1s - loss: 20.7745 - val_loss: 32.1112\n",
      "Epoch 5/10\n",
      " - 1s - loss: 18.5289 - val_loss: 76.0284\n",
      "Epoch 6/10\n",
      " - 1s - loss: 14.8645 - val_loss: 64.6500\n",
      "Epoch 7/10\n",
      " - 1s - loss: 13.2954 - val_loss: 149.5905\n",
      "Epoch 8/10\n",
      " - 1s - loss: 12.4266 - val_loss: 238.8981\n",
      "Epoch 9/10\n",
      " - 1s - loss: 11.7372 - val_loss: 263.8329\n",
      "Epoch 00009: early stopping\n",
      "3\n",
      "Train...\n",
      "Train on 3066 samples, validate on 1310 samples\n",
      "Epoch 1/10\n",
      " - 18s - loss: 158.6884 - val_loss: 3456.5154\n",
      "Epoch 2/10\n",
      " - 1s - loss: 28.4857 - val_loss: 1406.9842\n",
      "Epoch 3/10\n",
      " - 1s - loss: 25.8783 - val_loss: 890.5134\n",
      "Epoch 4/10\n",
      " - 1s - loss: 22.0102 - val_loss: 236.9658\n",
      "Epoch 5/10\n",
      " - 1s - loss: 18.0938 - val_loss: 21.3527\n",
      "Epoch 6/10\n",
      " - 1s - loss: 14.3010 - val_loss: 46.8046\n",
      "Epoch 7/10\n",
      " - 1s - loss: 12.4803 - val_loss: 205.4172\n",
      "Epoch 8/10\n",
      " - 1s - loss: 11.9469 - val_loss: 106.0474\n",
      "Epoch 9/10\n",
      " - 1s - loss: 10.5389 - val_loss: 490.3125\n",
      "Epoch 10/10\n",
      " - 1s - loss: 10.0005 - val_loss: 279.3241\n",
      "Epoch 00010: early stopping\n",
      "4\n",
      "Train...\n",
      "Train on 3066 samples, validate on 1310 samples\n",
      "Epoch 1/10\n",
      " - 18s - loss: 196.1520 - val_loss: 2855.8797\n",
      "Epoch 2/10\n",
      " - 1s - loss: 35.9643 - val_loss: 693.7943\n",
      "Epoch 3/10\n",
      " - 1s - loss: 28.9746 - val_loss: 525.9189\n",
      "Epoch 4/10\n",
      " - 1s - loss: 24.4804 - val_loss: 317.2670\n",
      "Epoch 5/10\n",
      " - 1s - loss: 20.0735 - val_loss: 56.7584\n",
      "Epoch 6/10\n",
      " - 1s - loss: 16.8987 - val_loss: 45.0012\n",
      "Epoch 7/10\n",
      " - 1s - loss: 14.0453 - val_loss: 67.1657\n",
      "Epoch 8/10\n",
      " - 1s - loss: 13.2217 - val_loss: 84.1955\n",
      "Epoch 9/10\n",
      " - 1s - loss: 12.2115 - val_loss: 111.7102\n",
      "Epoch 10/10\n",
      " - 1s - loss: 11.8672 - val_loss: 226.8388\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import numpy as np\n",
    "from keras import optimizers\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "\n",
    "print('Build model...')\n",
    "checkpointer = ModelCheckpoint(filepath=r\"G:\\215\\lstm6.hdf5\", verbose=0, save_best_only=True) # save best model\n",
    "\n",
    "for i in range(5):\n",
    "    print(i)\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(LSTM(32, dropout=0.1, recurrent_dropout=0.1, input_shape=(SEQUENCE_SIZE, 5),activation = 'relu'))\n",
    "    model.add(Dropout(0.10))\n",
    "    model.add(Dense(32,activation='relu'))\n",
    "    model.add(Dropout(0.10))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer='rmsprop')\n",
    "\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "    print('Train...')\n",
    "\n",
    "    model.fit(x_train,y_train,validation_data=(x_test,y_test),callbacks=[monitor,checkpointer],verbose=2, epochs=10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (MSE): 21.352689251227346\n",
      "Final score (RMSE): 4.6208970180287885\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "model.load_weights(r\"G:\\215\\lstm6.hdf5\")\n",
    "\n",
    "pred = model.predict(x_test)\n",
    "\n",
    "score = metrics.mean_squared_error(pred,y_test)\n",
    "print(\"Final score (MSE): {}\".format(score))\n",
    "\n",
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "print(\"Final score (RMSE): {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "0\n",
      "Train...\n",
      "Train on 3066 samples, validate on 1310 samples\n",
      "Epoch 1/10\n",
      " - 21s - loss: 99.7612 - val_loss: 5027.6310\n",
      "Epoch 2/10\n",
      " - 2s - loss: 31.6428 - val_loss: 4316.6737\n",
      "Epoch 3/10\n",
      " - 3s - loss: 21.0327 - val_loss: 1082.1966\n",
      "Epoch 4/10\n",
      " - 2s - loss: 16.8415 - val_loss: 39.2216\n",
      "Epoch 5/10\n",
      " - 2s - loss: 13.9256 - val_loss: 312.6530\n",
      "Epoch 6/10\n",
      " - 2s - loss: 10.8745 - val_loss: 389.3658\n",
      "Epoch 7/10\n",
      " - 2s - loss: 8.6794 - val_loss: 410.6969\n",
      "Epoch 8/10\n",
      " - 2s - loss: 7.9763 - val_loss: 439.2701\n",
      "Epoch 9/10\n",
      " - 2s - loss: 7.2590 - val_loss: 386.1109\n",
      "Epoch 00009: early stopping\n",
      "1\n",
      "Train...\n",
      "Train on 3066 samples, validate on 1310 samples\n",
      "Epoch 1/10\n",
      " - 25s - loss: 110.1284 - val_loss: 1345.4796\n",
      "Epoch 2/10\n",
      " - 2s - loss: 28.6433 - val_loss: 2837.3682\n",
      "Epoch 3/10\n",
      " - 2s - loss: 20.8132 - val_loss: 250.2706\n",
      "Epoch 4/10\n",
      " - 2s - loss: 18.3038 - val_loss: 78.1476\n",
      "Epoch 5/10\n",
      " - 2s - loss: 14.3069 - val_loss: 156.0328\n",
      "Epoch 6/10\n",
      " - 2s - loss: 11.7739 - val_loss: 109.3750\n",
      "Epoch 7/10\n",
      " - 2s - loss: 10.2151 - val_loss: 143.0853\n",
      "Epoch 8/10\n",
      " - 2s - loss: 8.9418 - val_loss: 162.2277\n",
      "Epoch 9/10\n",
      " - 2s - loss: 8.7738 - val_loss: 258.6533\n",
      "Epoch 00009: early stopping\n",
      "2\n",
      "Train...\n",
      "Train on 3066 samples, validate on 1310 samples\n",
      "Epoch 1/10\n",
      " - 27s - loss: 104.4428 - val_loss: 4398.3520\n",
      "Epoch 2/10\n",
      " - 2s - loss: 26.5895 - val_loss: 4741.3777\n",
      "Epoch 3/10\n",
      " - 2s - loss: 22.6125 - val_loss: 1819.5711\n",
      "Epoch 4/10\n",
      " - 2s - loss: 17.7601 - val_loss: 1106.8197\n",
      "Epoch 5/10\n",
      " - 2s - loss: 13.4087 - val_loss: 28.1203\n",
      "Epoch 6/10\n",
      " - 2s - loss: 11.1055 - val_loss: 261.9187\n",
      "Epoch 7/10\n",
      " - 2s - loss: 9.7323 - val_loss: 308.1007\n",
      "Epoch 8/10\n",
      " - 2s - loss: 8.5865 - val_loss: 216.4989\n",
      "Epoch 9/10\n",
      " - 2s - loss: 7.7218 - val_loss: 313.7296\n",
      "Epoch 10/10\n",
      " - 2s - loss: 6.4379 - val_loss: 618.2364\n",
      "Epoch 00010: early stopping\n",
      "3\n",
      "Train...\n",
      "Train on 3066 samples, validate on 1310 samples\n",
      "Epoch 1/10\n",
      " - 20s - loss: 89.0884 - val_loss: 12590.2864\n",
      "Epoch 2/10\n",
      " - 2s - loss: 29.6542 - val_loss: 4051.0942\n",
      "Epoch 3/10\n",
      " - 2s - loss: 20.7416 - val_loss: 1658.0859\n",
      "Epoch 4/10\n",
      " - 2s - loss: 16.0474 - val_loss: 248.9511\n",
      "Epoch 5/10\n",
      " - 2s - loss: 11.8702 - val_loss: 47.3731\n",
      "Epoch 6/10\n",
      " - 2s - loss: 9.1338 - val_loss: 686.1514\n",
      "Epoch 7/10\n",
      " - 2s - loss: 8.5715 - val_loss: 386.9641\n",
      "Epoch 8/10\n",
      " - 2s - loss: 7.0332 - val_loss: 672.7098\n",
      "Epoch 9/10\n",
      " - 2s - loss: 7.0188 - val_loss: 475.3741\n",
      "Epoch 10/10\n",
      " - 2s - loss: 6.3734 - val_loss: 444.8277\n",
      "Epoch 00010: early stopping\n",
      "4\n",
      "Train...\n",
      "Train on 3066 samples, validate on 1310 samples\n",
      "Epoch 1/10\n",
      " - 23s - loss: 101.8675 - val_loss: 4912.5750\n",
      "Epoch 2/10\n",
      " - 3s - loss: 26.6624 - val_loss: 916.1941\n",
      "Epoch 3/10\n",
      " - 3s - loss: 19.9280 - val_loss: 109.1351\n",
      "Epoch 4/10\n",
      " - 3s - loss: 15.8637 - val_loss: 62.4974\n",
      "Epoch 5/10\n",
      " - 3s - loss: 12.7763 - val_loss: 144.7545\n",
      "Epoch 6/10\n",
      " - 3s - loss: 10.8945 - val_loss: 173.8115\n",
      "Epoch 7/10\n",
      " - 3s - loss: 8.5906 - val_loss: 375.4378\n",
      "Epoch 8/10\n",
      " - 2s - loss: 8.2183 - val_loss: 276.4585\n",
      "Epoch 9/10\n",
      " - 3s - loss: 6.8086 - val_loss: 447.3558\n",
      "Epoch 00009: early stopping\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import numpy as np\n",
    "from keras import optimizers\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "\n",
    "print('Build model...')\n",
    "checkpointer = ModelCheckpoint(filepath=r\"G:\\215\\lstm7.hdf5\", verbose=0, save_best_only=True) # save best model\n",
    "\n",
    "for i in range(5):\n",
    "    print(i)\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(LSTM(64, dropout=0.1, recurrent_dropout=0.1, input_shape=(SEQUENCE_SIZE, 5),activation = 'relu'))\n",
    "    model.add(Dropout(0.10))\n",
    "    model.add(Dense(64,activation='relu'))\n",
    "    model.add(Dropout(0.10))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer='rmsprop')\n",
    "\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "    print('Train...')\n",
    "\n",
    "    model.fit(x_train,y_train,validation_data=(x_test,y_test),callbacks=[monitor,checkpointer],verbose=2, epochs=10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (MSE): 28.120287275837466\n",
      "Final score (RMSE): 5.302856520389503\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "model.load_weights(r\"G:\\215\\lstm7.hdf5\")\n",
    "\n",
    "pred = model.predict(x_test)\n",
    "\n",
    "score = metrics.mean_squared_error(pred,y_test)\n",
    "print(\"Final score (MSE): {}\".format(score))\n",
    "\n",
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "print(\"Final score (RMSE): {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
